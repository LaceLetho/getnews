"""
LLMåˆ†æå™¨

ä¸å¤§è¯­è¨€æ¨¡å‹APIé›†æˆï¼Œè¿›è¡Œå†…å®¹åˆ†æå’Œåˆ†ç±»ã€‚
"""

import json
import logging
import time
from typing import Dict, Any, List, Optional
import requests
from dataclasses import dataclass

from ..models import ContentItem, AnalysisResult
from .prompt_manager import PromptManager, DynamicCategoryManager


@dataclass
class LLMResponse:
    """LLMå“åº”æ•°æ®"""
    category: str
    confidence: float
    reasoning: str
    should_ignore: bool
    key_points: List[str]


class LLMAnalyzer:
    """LLMåˆ†æå™¨"""
    
    def __init__(self, api_key: str, model: str = "MiniMax-M2.1", 
                 prompt_config_path: str = "./prompts/analysis_prompt.json",
                 api_base_url: str = "https://api.minimax.chat/v1",
                 mock_mode: bool = False):
        """
        åˆå§‹åŒ–LLMåˆ†æå™¨
        
        Args:
            api_key: LLM APIå¯†é’¥
            model: æ¨¡å‹åç§° (æ”¯æŒ MiniMax-M2.1, MiniMax-M2.1-lightning, MiniMax-M2, gpt-4ç­‰)
            prompt_config_path: æç¤ºè¯é…ç½®æ–‡ä»¶è·¯å¾„
            api_base_url: APIåŸºç¡€URL
            mock_mode: æ˜¯å¦ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        """
        self.api_key = api_key
        self.model = model
        self.mock_mode = mock_mode
        self.prompt_manager = PromptManager(prompt_config_path)
        self.category_manager = DynamicCategoryManager(prompt_config_path)
        self.logger = logging.getLogger(__name__)
        
        # æ ¹æ®æ¨¡å‹è‡ªåŠ¨é€‰æ‹©APIé…ç½®
        if model.startswith("MiniMax"):
            # ä½¿ç”¨ MiniMax å¹³å° API ç«¯ç‚¹ï¼ˆæ–° API key æ ¼å¼ï¼‰
            self.api_base_url = "https://platform.minimax.io/v1"
            self.use_minimax_format = True
        elif model.startswith("gpt"):
            self.api_base_url = "https://api.openai.com/v1"
            self.use_minimax_format = False
        else:
            self.api_base_url = api_base_url
            self.use_minimax_format = False
            
        self.headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        # é‡è¯•é…ç½®
        self.max_retries = 3
        self.retry_delay = 1.0
        
        if mock_mode:
            self.logger.info("LLMåˆ†æå™¨è¿è¡Œåœ¨æ¨¡æ‹Ÿæ¨¡å¼")
        
    def analyze_content(self, content: str, title: str = "", source: str = "", content_id: str = "") -> AnalysisResult:
        """
        åˆ†æå•ä¸ªå†…å®¹
        
        Args:
            content: å†…å®¹æ–‡æœ¬
            title: æ ‡é¢˜
            source: æ¥æº
            content_id: å†…å®¹ID
            
        Returns:
            åˆ†æç»“æœ
        """
        try:
            # æ„å»ºæç¤ºè¯
            prompt = self.prompt_manager.build_analysis_prompt(content, title, source)
            
            # è°ƒç”¨LLM API
            llm_response = self._call_llm_api(prompt)
            
            # è§£æå“åº”
            parsed_response = self.parse_llm_response(llm_response)
            
            # éªŒè¯åˆ†ç±»
            if not self._validate_category_response(parsed_response.category):
                self.logger.warning(f"æ— æ•ˆåˆ†ç±»: {parsed_response.category}ï¼Œè®¾ä¸ºæœªåˆ†ç±»")
                parsed_response.category = "æœªåˆ†ç±»"
            
            # åˆ›å»ºåˆ†æç»“æœ
            result = AnalysisResult(
                content_id=content_id or "temp_id",  # æä¾›é»˜è®¤ID
                category=parsed_response.category,
                confidence=parsed_response.confidence,
                reasoning=parsed_response.reasoning,
                should_ignore=parsed_response.should_ignore,
                key_points=parsed_response.key_points
            )
            
            self.logger.info(f"å†…å®¹åˆ†æå®Œæˆ: {parsed_response.category} (ç½®ä¿¡åº¦: {parsed_response.confidence})")
            return result
            
        except Exception as e:
            self.logger.error(f"å†…å®¹åˆ†æå¤±è´¥: {e}")
            # è¿”å›é»˜è®¤ç»“æœ
            return AnalysisResult(
                content_id=content_id or "temp_id",
                category="æœªåˆ†ç±»",
                confidence=0.0,
                reasoning=f"åˆ†æå¤±è´¥: {str(e)}",
                should_ignore=False,
                key_points=[]
            )
    
    def batch_analyze(self, items: List[ContentItem]) -> List[AnalysisResult]:
        """
        æ‰¹é‡åˆ†æå†…å®¹
        
        Args:
            items: å†…å®¹é¡¹åˆ—è¡¨
            
        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        results = []
        
        # è·å–æ‰¹é‡å¤§å°é…ç½®
        llm_settings = self.prompt_manager.get_llm_settings()
        batch_size = llm_settings.get("batch_size", 10)
        
        self.logger.info(f"å¼€å§‹æ‰¹é‡åˆ†æ {len(items)} ä¸ªå†…å®¹é¡¹ï¼Œæ‰¹é‡å¤§å°: {batch_size}")
        
        for i in range(0, len(items), batch_size):
            batch = items[i:i + batch_size]
            
            for item in batch:
                result = self.analyze_content(item.content, item.title, item.source_name)
                result.content_id = item.id
                results.append(result)
                
                # æ·»åŠ å»¶è¿Ÿé¿å…APIé™åˆ¶
                time.sleep(0.1)
            
            # æ‰¹æ¬¡é—´å»¶è¿Ÿ
            if i + batch_size < len(items):
                time.sleep(1.0)
        
        self.logger.info(f"æ‰¹é‡åˆ†æå®Œæˆï¼Œå…±å¤„ç† {len(results)} ä¸ªé¡¹ç›®")
        return results
    
    def classify_content(self, content: str) -> str:
        """
        ç®€å•åˆ†ç±»å†…å®¹ï¼ˆä¸è¿”å›è¯¦ç»†åˆ†æï¼‰
        
        Args:
            content: å†…å®¹æ–‡æœ¬
            
        Returns:
            åˆ†ç±»åç§°
        """
        result = self.analyze_content(content)
        return result.category
    
    def should_ignore_content(self, content: str) -> bool:
        """
        åˆ¤æ–­å†…å®¹æ˜¯å¦åº”è¯¥å¿½ç•¥
        
        Args:
            content: å†…å®¹æ–‡æœ¬
            
        Returns:
            æ˜¯å¦åº”è¯¥å¿½ç•¥
        """
        result = self.analyze_content(content)
        return result.should_ignore
    
    def parse_llm_response(self, response: str) -> LLMResponse:
        """
        è§£æLLMå“åº”
        
        Args:
            response: LLMå“åº”æ–‡æœ¬
            
        Returns:
            è§£æåçš„å“åº”å¯¹è±¡
        """
        try:
            # æ¸…ç†å“åº”æ–‡æœ¬ï¼Œç§»é™¤ <think> æ ‡ç­¾å’Œå…¶ä»–éJSONå†…å®¹
            cleaned_response = self._clean_response_text(response)
            
            # å°è¯•è§£æJSONå“åº”
            response_data = json.loads(cleaned_response)
            
            return LLMResponse(
                category=response_data.get("category", "æœªåˆ†ç±»"),
                confidence=float(response_data.get("confidence", 0.0)),
                reasoning=response_data.get("reasoning", ""),
                should_ignore=bool(response_data.get("should_ignore", False)),
                key_points=response_data.get("key_points", [])
            )
            
        except json.JSONDecodeError as e:
            self.logger.error(f"è§£æLLMå“åº”JSONå¤±è´¥: {e}")
            # å°è¯•ä»æ–‡æœ¬ä¸­æå–ä¿¡æ¯
            return self._parse_text_response(response)
        except Exception as e:
            self.logger.error(f"è§£æLLMå“åº”å¤±è´¥: {e}")
            return LLMResponse(
                category="æœªåˆ†ç±»",
                confidence=0.0,
                reasoning=f"è§£æå¤±è´¥: {str(e)}",
                should_ignore=False,
                key_points=[]
            )
    
    def _clean_response_text(self, response: str) -> str:
        """
        æ¸…ç†å“åº”æ–‡æœ¬ï¼Œæå–JSONéƒ¨åˆ†
        
        Args:
            response: åŸå§‹å“åº”æ–‡æœ¬
            
        Returns:
            æ¸…ç†åçš„JSONå­—ç¬¦ä¸²
        """
        import re
        
        # ç§»é™¤ <think> æ ‡ç­¾åŠå…¶å†…å®¹
        response = re.sub(r'<think>.*?</think>', '', response, flags=re.DOTALL)
        
        # æŸ¥æ‰¾JSONå¯¹è±¡
        json_match = re.search(r'\{.*\}', response, flags=re.DOTALL)
        if json_match:
            return json_match.group(0).strip()
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œè¿”å›åŸå§‹å“åº”
        return response.strip()
    
    def reload_prompt_config(self) -> None:
        """é‡æ–°åŠ è½½æç¤ºè¯é…ç½®"""
        self.prompt_manager.reload_configuration()
        self.category_manager.reload_categories()
        self.logger.info("æç¤ºè¯é…ç½®å·²é‡æ–°åŠ è½½")
    
    def _call_llm_api(self, prompt: str) -> str:
        """
        è°ƒç”¨LLM API
        
        Args:
            prompt: æç¤ºè¯
            
        Returns:
            APIå“åº”æ–‡æœ¬
        """
        if self.mock_mode:
            return self._generate_mock_response(prompt)
            
        llm_settings = self.prompt_manager.get_llm_settings()
        
        if self.model.startswith("MiniMax"):
            # ä½¿ç”¨ OpenAI å…¼å®¹æ ¼å¼ï¼ˆé€‚ç”¨äº platform.minimax.ioï¼‰
            payload = {
                "model": self.model,
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "temperature": llm_settings.get("temperature", 0.1),
                "max_tokens": llm_settings.get("max_tokens", 1000)
            }
            endpoint = f"{self.api_base_url}/chat/completions"
        else:
            # ä½¿ç”¨ OpenAI æ ¼å¼
            payload = {
                "model": self.model,
                "messages": [
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                "temperature": llm_settings.get("temperature", 0.1),
                "max_tokens": llm_settings.get("max_tokens", 1000)
            }
            endpoint = f"{self.api_base_url}/chat/completions"
        
        for attempt in range(self.max_retries):
            try:
                response = requests.post(
                    endpoint,
                    headers=self.headers,
                    json=payload,
                    timeout=30
                )
                
                if response.status_code == 200:
                    response_data = response.json()
                    
                    # ç»Ÿä¸€ä½¿ç”¨ OpenAI æ ¼å¼è§£æ
                    if "choices" in response_data and len(response_data["choices"]) > 0:
                        choice = response_data["choices"][0]
                        if "message" in choice and "content" in choice["message"]:
                            return choice["message"]["content"]
                        elif "text" in choice:
                            return choice["text"]
                    
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ ‡å‡†æ ¼å¼ï¼Œè®°å½•é”™è¯¯
                    self.logger.error(f"æ— æ³•è§£æå“åº”æ ¼å¼: {response_data}")
                    return ""
                        
                elif response.status_code == 429:
                    # é€Ÿç‡é™åˆ¶ï¼Œç­‰å¾…æ›´é•¿æ—¶é—´
                    wait_time = self.retry_delay * (2 ** attempt)
                    self.logger.warning(f"APIé€Ÿç‡é™åˆ¶ï¼Œç­‰å¾… {wait_time} ç§’åé‡è¯•")
                    time.sleep(wait_time)
                else:
                    self.logger.error(f"APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
                    if attempt == self.max_retries - 1:
                        raise Exception(f"APIè°ƒç”¨å¤±è´¥: {response.status_code}")
                    
            except requests.exceptions.Timeout:
                self.logger.warning(f"APIè°ƒç”¨è¶…æ—¶ï¼Œç¬¬ {attempt + 1} æ¬¡é‡è¯•")
                if attempt == self.max_retries - 1:
                    raise Exception("APIè°ƒç”¨è¶…æ—¶")
                time.sleep(self.retry_delay)
            except Exception as e:
                self.logger.error(f"APIè°ƒç”¨å¼‚å¸¸: {e}")
                if attempt == self.max_retries - 1:
                    raise
                time.sleep(self.retry_delay)
        
        raise Exception("APIè°ƒç”¨å¤±è´¥ï¼Œå·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°")
    
    def _generate_mock_response(self, prompt: str) -> str:
        """
        ç”Ÿæˆæ¨¡æ‹Ÿå“åº”ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        
        Args:
            prompt: æç¤ºè¯
            
        Returns:
            æ¨¡æ‹Ÿçš„JSONå“åº”
        """
        # ä»æç¤ºè¯ä¸­æå–å®é™…è¦åˆ†æçš„å†…å®¹
        # æŸ¥æ‰¾ "å†…å®¹ï¼š" åé¢çš„å®é™…å†…å®¹
        content_start = prompt.find("å†…å®¹ï¼š")
        if content_start != -1:
            content_section = prompt[content_start + 3:]  # è·³è¿‡ "å†…å®¹ï¼š"
            # æŸ¥æ‰¾å†…å®¹ç»“æŸä½ç½®ï¼ˆé€šå¸¸æ˜¯ "æ¥æºï¼š" æˆ– "---"ï¼‰
            content_end = content_section.find("æ¥æºï¼š")
            if content_end == -1:
                content_end = content_section.find("---")
            if content_end != -1:
                actual_content = content_section[:content_end].strip()
            else:
                actual_content = content_section.strip()
        else:
            # å¦‚æœæ‰¾ä¸åˆ°æ ‡å‡†æ ¼å¼ï¼Œä½¿ç”¨æ•´ä¸ªæç¤ºè¯
            actual_content = prompt
        
        content_lower = actual_content.lower()
        
        # è·å–å¯ç”¨çš„åˆ†ç±»åˆ—è¡¨
        try:
            categories = self.category_manager.load_categories()
            available_categories = list(categories.keys())
        except Exception:
            # å¦‚æœæ— æ³•åŠ è½½é…ç½®ï¼Œä½¿ç”¨é»˜è®¤åˆ†ç±»
            available_categories = ["å¤§æˆ·åŠ¨å‘", "åˆ©ç‡äº‹ä»¶", "ç¾å›½æ”¿åºœç›‘ç®¡æ”¿ç­–", "å®‰å…¨äº‹ä»¶", "æ–°äº§å“", "å¸‚åœºæ–°ç°è±¡"]
        
        # åŸºäºå†…å®¹å…³é”®è¯è¿›è¡Œæ™ºèƒ½åˆ†ç±»åŒ¹é…
        category_keywords = {
            # å¤§æˆ·åŠ¨å‘ç›¸å…³å…³é”®è¯
            "å¤§æˆ·åŠ¨å‘": ["15000", "eth", "binance", "å·¨é²¸åœ°å€è½¬ç§»", "è½¬ç§»", "å·¨é²¸", "å¤§æˆ·", "èµ„é‡‘æµåŠ¨"],
            # åˆ©ç‡äº‹ä»¶ç›¸å…³å…³é”®è¯  
            "åˆ©ç‡äº‹ä»¶": ["ç¾è”å‚¨", "ä¼šè®®çºªè¦", "é™æ¯", "é²å¨å°”", "é€šèƒ€æ•°æ®", "fomc", "åˆ©ç‡", "å§”å‘˜"],
            # ç›‘ç®¡æ”¿ç­–ç›¸å…³å…³é”®è¯
            "ç¾å›½æ”¿åºœç›‘ç®¡æ”¿ç­–": ["sec", "ç›‘ç®¡", "æ”¿ç­–", "æ³•æ¡ˆ", "cftc", "è´¢æ”¿éƒ¨"],
            # å®‰å…¨äº‹ä»¶ç›¸å…³å…³é”®è¯
            "å®‰å…¨äº‹ä»¶": ["é»‘å®¢æ”»å‡»", "defiåè®®", "500ä¸‡ç¾å…ƒ", "é‡å…¥æ¼æ´", "è¢«ç›—", "å®‰å…¨", "æ¼æ´", "æ”»å‡»"],
            # æ–°äº§å“ç›¸å…³å…³é”®è¯
            "æ–°äº§å“": ["æ–°é¡¹ç›®", "åè®®", "åˆ›æ–°", "å‘å¸ƒ", "ä¸Šçº¿"],
            # å¸‚åœºæ–°ç°è±¡ç›¸å…³å…³é”®è¯
            "å¸‚åœºæ–°ç°è±¡": ["æ–°è¶‹åŠ¿", "é“¾ä¸Šæ•°æ®", "å¼‚å¸¸", "æ–°æ¨¡å¼", "ç°è±¡"]
        }
        
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥å¿½ç•¥ï¼ˆå…ˆæ£€æŸ¥å¿½ç•¥æ¡ä»¶ï¼‰
        ignore_keywords = ["ğŸš€", "è¶…é«˜æ”¶ç›Šç‡", "ç«‹å³å‚ä¸", "åƒè½½éš¾é€¢"]
        should_ignore = any(keyword in content_lower for keyword in ignore_keywords)
        
        if should_ignore:
            return json.dumps({
                "category": "å¿½ç•¥",
                "confidence": 0.95,
                "reasoning": "å†…å®¹ç–‘ä¼¼å¹¿å‘Šæˆ–æ¨å¹¿è½¯æ–‡ï¼Œåº”è¯¥å¿½ç•¥ã€‚",
                "should_ignore": True,
                "key_points": ["å¹¿å‘Šå†…å®¹", "æ¨å¹¿ä¿¡æ¯"]
            }, ensure_ascii=False)
        
        # æŸ¥æ‰¾åŒ¹é…çš„åˆ†ç±»
        matched_category = None
        max_matches = 0
        
        for category_name in available_categories:
            if category_name in category_keywords:
                keywords = category_keywords[category_name]
                matches = sum(1 for keyword in keywords if keyword in content_lower)
                if matches > max_matches:
                    max_matches = matches
                    matched_category = category_name
        
        if matched_category and max_matches > 0:
            # æ ¹æ®åŒ¹é…çš„åˆ†ç±»ç”Ÿæˆå“åº”
            confidence = min(0.95, 0.7 + (max_matches * 0.05))
            return json.dumps({
                "category": matched_category,
                "confidence": confidence,
                "reasoning": f"å†…å®¹ç¬¦åˆ{matched_category}çš„åˆ†ç±»æ ‡å‡†ï¼Œæ£€æµ‹åˆ°ç›¸å…³å…³é”®è¯ã€‚",
                "should_ignore": False,
                "key_points": [f"{matched_category}ç›¸å…³", "å…³é”®è¯åŒ¹é…"]
            }, ensure_ascii=False)
        else:
            return json.dumps({
                "category": "æœªåˆ†ç±»",
                "confidence": 0.60,
                "reasoning": "å†…å®¹ä¸ç¬¦åˆé¢„å®šä¹‰çš„åˆ†ç±»æ ‡å‡†ï¼Œå½’ä¸ºæœªåˆ†ç±»ã€‚",
                "should_ignore": False,
                "key_points": ["ä¸€èˆ¬ä¿¡æ¯"]
            }, ensure_ascii=False)
    
    def get_available_categories(self) -> List[str]:
        """è·å–å¯ç”¨çš„åˆ†ç±»åˆ—è¡¨"""
        return self.category_manager.get_category_list()
    
    def update_classification_config(self, new_config: Dict[str, Any]) -> None:
        """æ›´æ–°åˆ†ç±»é…ç½®"""
        # è¿™é‡Œå¯ä»¥å®ç°é…ç½®æ›´æ–°é€»è¾‘
        # ç›®å‰é€šè¿‡é‡æ–°åŠ è½½é…ç½®æ–‡ä»¶å®ç°
        self.reload_prompt_config()
        self.logger.info("åˆ†ç±»é…ç½®å·²æ›´æ–°")
        """
        éªŒè¯åˆ†ç±»å“åº”æœ‰æ•ˆæ€§
        
        Args:
            category: åˆ†ç±»åç§°
            
        Returns:
            æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            categories = self.category_manager.load_categories()
            valid_categories = list(categories.keys()) + ["æœªåˆ†ç±»", "å¿½ç•¥"]
            return category in valid_categories
        except Exception:
            return False
    
    def _parse_text_response(self, response: str) -> LLMResponse:
        """
        ä»æ–‡æœ¬å“åº”ä¸­æå–ä¿¡æ¯ï¼ˆå¤‡ç”¨è§£ææ–¹æ³•ï¼‰
        
        Args:
            response: å“åº”æ–‡æœ¬
            
        Returns:
            è§£æåçš„å“åº”å¯¹è±¡
        """
        # ç®€å•çš„æ–‡æœ¬è§£æé€»è¾‘
        category = "æœªåˆ†ç±»"
        confidence = 0.5
        reasoning = response[:200] + "..." if len(response) > 200 else response
        should_ignore = "å¿½ç•¥" in response or "ignore" in response.lower()
        key_points = []
        
        # å°è¯•ä»æ–‡æœ¬ä¸­æå–åˆ†ç±»
        categories = self.category_manager.load_categories()
        for cat_name in categories.keys():
            if cat_name in response:
                category = cat_name
                break
        
        return LLMResponse(
            category=category,
            confidence=confidence,
            reasoning=reasoning,
            should_ignore=should_ignore,
            key_points=key_points
        )
    
    def get_available_categories(self) -> List[str]:
        """è·å–å¯ç”¨çš„åˆ†ç±»åˆ—è¡¨"""
        return self.category_manager.get_category_list()
    
    def update_classification_config(self, new_config: Dict[str, Any]) -> None:
        """æ›´æ–°åˆ†ç±»é…ç½®"""
        # è¿™é‡Œå¯ä»¥å®ç°é…ç½®æ›´æ–°é€»è¾‘
        # ç›®å‰é€šè¿‡é‡æ–°åŠ è½½é…ç½®æ–‡ä»¶å®ç°
        self.reload_prompt_config()
        self.logger.info("åˆ†ç±»é…ç½®å·²æ›´æ–°")
    
    def _validate_category_response(self, category: str) -> bool:
        """
        éªŒè¯åˆ†ç±»å“åº”æœ‰æ•ˆæ€§
        
        Args:
            category: åˆ†ç±»åç§°
            
        Returns:
            æ˜¯å¦æœ‰æ•ˆ
        """
        try:
            categories = self.category_manager.load_categories()
            valid_categories = list(categories.keys()) + ["æœªåˆ†ç±»", "å¿½ç•¥"]
            return category in valid_categories
        except Exception:
            return False


class ContentClassifier:
    """å†…å®¹åˆ†ç±»å™¨"""
    
    def __init__(self, llm_analyzer: LLMAnalyzer):
        """
        åˆå§‹åŒ–å†…å®¹åˆ†ç±»å™¨
        
        Args:
            llm_analyzer: LLMåˆ†æå™¨å®ä¾‹
        """
        self.llm_analyzer = llm_analyzer
        self.logger = logging.getLogger(__name__)
        self.classified_items: Dict[str, List[ContentItem]] = {}
    
    def classify_item(self, item: ContentItem, analysis: AnalysisResult) -> str:
        """
        åˆ†ç±»å•ä¸ªå†…å®¹é¡¹
        
        Args:
            item: å†…å®¹é¡¹
            analysis: åˆ†æç»“æœ
            
        Returns:
            åˆ†ç±»åç§°
        """
        category = analysis.category
        
        # å­˜å‚¨åˆ†ç±»ç»“æœ
        if category not in self.classified_items:
            self.classified_items[category] = []
        
        self.classified_items[category].append(item)
        
        self.logger.debug(f"å†…å®¹é¡¹å·²åˆ†ç±»: {item.title[:50]}... -> {category}")
        return category
    
    def get_category_items(self, category: str) -> List[ContentItem]:
        """
        è·å–æŒ‡å®šåˆ†ç±»çš„å†…å®¹é¡¹
        
        Args:
            category: åˆ†ç±»åç§°
            
        Returns:
            å†…å®¹é¡¹åˆ—è¡¨
        """
        return self.classified_items.get(category, [])
    
    def generate_category_summary(self, category: str) -> str:
        """
        ç”Ÿæˆåˆ†ç±»æ‘˜è¦
        
        Args:
            category: åˆ†ç±»åç§°
            
        Returns:
            åˆ†ç±»æ‘˜è¦æ–‡æœ¬
        """
        items = self.get_category_items(category)
        
        if not items:
            return f"{category}: æš‚æ— ç›¸å…³å†…å®¹"
        
        summary = f"{category} ({len(items)}æ¡):\n"
        for i, item in enumerate(items[:5], 1):  # æœ€å¤šæ˜¾ç¤º5æ¡
            summary += f"{i}. {item.title}\n"
        
        if len(items) > 5:
            summary += f"... è¿˜æœ‰ {len(items) - 5} æ¡å†…å®¹\n"
        
        return summary
    
    def clear_classifications(self) -> None:
        """æ¸…ç©ºåˆ†ç±»ç»“æœ"""
        self.classified_items.clear()
        self.logger.info("åˆ†ç±»ç»“æœå·²æ¸…ç©º")
    
    def get_all_categories(self) -> List[str]:
        """è·å–æ‰€æœ‰åˆ†ç±»åç§°"""
        return list(self.classified_items.keys())
    
    def get_classification_stats(self) -> Dict[str, int]:
        """è·å–åˆ†ç±»ç»Ÿè®¡ä¿¡æ¯"""
        return {category: len(items) for category, items in self.classified_items.items()}
    
    def get_available_categories(self) -> List[str]:
        """è·å–å¯ç”¨çš„åˆ†ç±»åˆ—è¡¨"""
        return self.llm_analyzer.get_available_categories()
    
    def validate_category(self, category: str) -> bool:
        """éªŒè¯åˆ†ç±»æ˜¯å¦æœ‰æ•ˆ"""
        return self.llm_analyzer._validate_category_response(category)
    
    def update_category_config(self, new_config: Dict[str, Any]) -> None:
        """æ›´æ–°åˆ†ç±»é…ç½®"""
        self.llm_analyzer.update_classification_config(new_config)