"""
X/Twitterçˆ¬å–å™¨å•å…ƒæµ‹è¯•

æµ‹è¯•åŸºäºbirdå·¥å…·çš„X/Twitterçˆ¬å–å™¨åŠŸèƒ½ã€‚
éªŒè¯éœ€æ±‚ 4.1, 4.2, 4.7, 4.8
"""

import pytest
import json
import time
from unittest.mock import Mock, patch, MagicMock
from datetime import datetime, timedelta
from typing import Dict, Any, List

from crypto_news_analyzer.crawlers.x_crawler import XCrawler
from crypto_news_analyzer.models import XSource, ContentItem, CrawlResult, BirdConfig, BirdResult
from crypto_news_analyzer.utils.errors import (
    AuthenticationError, CrawlerError
)


class TestXCrawlerInitialization:
    """Xçˆ¬å–å™¨åˆå§‹åŒ–æµ‹è¯•"""
    
    @patch('crypto_news_analyzer.crawlers.x_crawler.BirdWrapper')
    def test_valid_initialization(self, mock_bird_wrapper):
        """æµ‹è¯•æœ‰æ•ˆçš„åˆå§‹åŒ–å‚æ•°"""
        # æ¨¡æ‹ŸBirdWrapperæˆåŠŸåˆå§‹åŒ–
        mock_wrapper = Mock()
        mock_wrapper.test_connection.return_value = True
        mock_bird_wrapper.return_value = mock_wrapper
        
        crawler = XCrawler(time_window_hours=24)
        
        assert crawler.time_window_hours == 24
        assert crawler.authenticated == True
        assert hasattr(crawler, 'bird_wrapper')
        assert hasattr(crawler, 'logger')
        
        # éªŒè¯BirdWrapperè¢«æ­£ç¡®åˆå§‹åŒ–
        mock_bird_wrapper.assert_called_once_with(config=None)
        mock_wrapper.test_connection.assert_called_once()
    
    @patch('crypto_news_analyzer.crawlers.x_crawler.BirdWrapper')
    def test_initialization_with_bird_config(self, mock_bird_wrapper):
        """æµ‹è¯•ä½¿ç”¨è‡ªå®šä¹‰BirdConfigåˆå§‹åŒ–"""
        mock_wrapper = Mock()
        mock_wrapper.test_connection.return_value = True
        mock_bird_wrapper.return_value = mock_wrapper
        
        bird_config = BirdConfig(
            executable_path="/custom/path/bird",
            timeout_seconds=600,
            max_retries=5
        )
        
        crawler = XCrawler(time_window_hours=12, bird_config=bird_config)
        
        assert crawler.time_window_hours == 12
        mock_bird_wrapper.assert_called_once_with(config=bird_config)
    
    @patch('crypto_news_analyzer.crawlers.x_crawler.BirdWrapper')
    def test_initialization_bird_wrapper_failure(self, mock_bird_wrapper):
        """æµ‹è¯•BirdWrapperåˆå§‹åŒ–å¤±è´¥"""
        mock_bird_wrapper.side_effect = RuntimeError("Birdå·¥å…·ä¸å¯ç”¨")
        
        with pytest.raises(CrawlerError, match="Birdå·¥å…·åˆå§‹åŒ–å¤±è´¥"):
            XCrawler(time_window_hours=24)
    
    @patch('crypto_news_analyzer.crawlers.x_crawler.BirdWrapper')
    def test_initialization_connection_test_failure(self, mock_bird_wrapper):
        """æµ‹è¯•è¿æ¥æµ‹è¯•å¤±è´¥ä½†åˆå§‹åŒ–æˆåŠŸ"""
        mock_wrapper = Mock()
        mock_wrapper.test_connection.return_value = False
        mock_bird_wrapper.return_value = mock_wrapper
        
        crawler = XCrawler(time_window_hours=24)
        
        # åˆå§‹åŒ–åº”è¯¥æˆåŠŸï¼Œä½†è®¤è¯çŠ¶æ€ä¸ºFalse
        assert crawler.authenticated == False
        assert hasattr(crawler, 'bird_wrapper')


class TestXCrawlerAuthentication:
    """Xçˆ¬å–å™¨è®¤è¯æœºåˆ¶æµ‹è¯•"""
    
    def setup_method(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        with patch('crypto_news_analyzer.crawlers.x_crawler.BirdWrapper') as mock_bird_wrapper:
            mock_wrapper = Mock()
            mock_wrapper.test_connection.return_value = True
            mock_bird_wrapper.return_value = mock_wrapper
            
            self.crawler = XCrawler(time_window_hours=24)
            self.mock_bird_wrapper = self.crawler.bird_wrapper
    
    def test_successful_authentication(self):
        """æµ‹è¯•æˆåŠŸè®¤è¯"""
        self.mock_bird_wrapper.test_connection.return_value = True
        
        result = self.crawler.authenticate()
        
        assert result == True
        assert self.crawler.authenticated == True
        self.mock_bird_wrapper.test_connection.assert_called()
    
    def test_authentication_failure(self):
        """æµ‹è¯•è®¤è¯å¤±è´¥"""
        self.mock_bird_wrapper.test_connection.return_value = False
        
        result = self.crawler.authenticate()
        
        assert result == False
        assert self.crawler.authenticated == False
    
    def test_authentication_exception(self):
        """æµ‹è¯•è®¤è¯è¿‡ç¨‹ä¸­çš„å¼‚å¸¸"""
        self.mock_bird_wrapper.test_connection.side_effect = Exception("è¿æ¥é”™è¯¯")
        
        result = self.crawler.authenticate()
        
        assert result == False
        assert self.crawler.authenticated == False


class TestXCrawlerListCrawling:
    """Xçˆ¬å–å™¨åˆ—è¡¨çˆ¬å–æµ‹è¯•"""
    
    def setup_method(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        with patch('crypto_news_analyzer.crawlers.x_crawler.BirdWrapper') as mock_bird_wrapper:
            mock_wrapper = Mock()
            mock_wrapper.test_connection.return_value = True
            mock_bird_wrapper.return_value = mock_wrapper
            
            self.crawler = XCrawler(time_window_hours=24)
            self.mock_bird_wrapper = self.crawler.bird_wrapper
    
    def test_extract_list_id_valid_url(self):
        """æµ‹è¯•ä»æœ‰æ•ˆURLæå–åˆ—è¡¨ID"""
        valid_urls = [
            "https://x.com/i/lists/1234567890",
            "https://x.com/i/lists/9876543210123456",
            "https://twitter.com/i/lists/1111111111"
        ]
        
        for url in valid_urls:
            list_id = self.crawler._extract_list_id_from_url(url)
            assert list_id is not None
            assert list_id.isdigit()
    
    def test_extract_list_id_invalid_url(self):
        """æµ‹è¯•ä»æ— æ•ˆURLæå–åˆ—è¡¨ID"""
        invalid_urls = [
            "https://x.com/user/profile",
            "invalid_url",
            "",
            "https://x.com/i/lists/"
        ]
        
        for url in invalid_urls:
            list_id = self.crawler._extract_list_id_from_url(url)
            assert list_id is None
    
    def test_crawl_list_success(self):
        """æµ‹è¯•æˆåŠŸçˆ¬å–åˆ—è¡¨"""
        list_url = "https://x.com/i/lists/1234567890"
        
        # æ¨¡æ‹Ÿbirdå·¥å…·è¿”å›æˆåŠŸç»“æœ
        mock_result = BirdResult(
            success=True,
            output='[{"id": "123", "text": "æµ‹è¯•æ¨æ–‡", "created_at": "Wed Oct 10 20:19:24 +0000 2018", "user": {"screen_name": "test_user"}}]',
            error="",
            exit_code=0,
            execution_time=1.5,
            command=["bird", "list", "--id", "1234567890"]
        )
        
        self.mock_bird_wrapper.fetch_list_tweets.return_value = mock_result
        self.mock_bird_wrapper.parse_tweet_data.return_value = [
            {
                "id": "123",
                "text": "æµ‹è¯•æ¨æ–‡",
                "created_at": "Wed Oct 10 20:19:24 +0000 2018",
                "user": {"screen_name": "test_user"}
            }
        ]
        
        # ç¡®ä¿è®¤è¯æˆåŠŸ
        self.crawler.authenticated = True
        
        result = self.crawler.crawl_list(list_url)
        
        assert isinstance(result, list)
        assert len(result) >= 0  # å¯èƒ½å› ä¸ºæ—¶é—´çª—å£è¿‡æ»¤è€Œä¸ºç©º
        
        # éªŒè¯birdå·¥å…·è¢«æ­£ç¡®è°ƒç”¨
        self.mock_bird_wrapper.fetch_list_tweets.assert_called_once_with("1234567890", count=100)
    
    def test_crawl_list_invalid_url(self):
        """æµ‹è¯•çˆ¬å–æ— æ•ˆåˆ—è¡¨URL"""
        invalid_url = "https://x.com/invalid/url"
        
        with pytest.raises(CrawlerError, match="æ— æ•ˆçš„åˆ—è¡¨URL"):
            self.crawler.crawl_list(invalid_url)
    
    def test_crawl_list_authentication_required(self):
        """æµ‹è¯•åˆ—è¡¨çˆ¬å–éœ€è¦è®¤è¯"""
        list_url = "https://x.com/i/lists/1234567890"
        
        # æ¨¡æ‹Ÿæœªè®¤è¯çŠ¶æ€
        self.crawler.authenticated = False
        self.mock_bird_wrapper.test_connection.return_value = False
        
        with pytest.raises(CrawlerError, match="çˆ¬å–Xåˆ—è¡¨å¤±è´¥"):
            self.crawler.crawl_list(list_url)
    
    def test_crawl_list_bird_tool_failure(self):
        """æµ‹è¯•birdå·¥å…·æ‰§è¡Œå¤±è´¥"""
        list_url = "https://x.com/i/lists/1234567890"
        
        # æ¨¡æ‹Ÿbirdå·¥å…·è¿”å›å¤±è´¥ç»“æœ
        mock_result = BirdResult(
            success=False,
            output="",
            error="è®¤è¯å¤±è´¥",
            exit_code=1,
            execution_time=0.5,
            command=["bird", "list", "--id", "1234567890"]
        )
        
        self.mock_bird_wrapper.fetch_list_tweets.return_value = mock_result
        self.crawler.authenticated = True
        
        with pytest.raises(CrawlerError, match="Birdå·¥å…·è·å–åˆ—è¡¨æ¨æ–‡å¤±è´¥"):
            self.crawler.crawl_list(list_url)


class TestXCrawlerTimelineCrawling:
    """Xçˆ¬å–å™¨æ—¶é—´çº¿çˆ¬å–æµ‹è¯•"""
    
    def setup_method(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        with patch('crypto_news_analyzer.crawlers.x_crawler.BirdWrapper') as mock_bird_wrapper:
            mock_wrapper = Mock()
            mock_wrapper.test_connection.return_value = True
            mock_bird_wrapper.return_value = mock_wrapper
            
            self.crawler = XCrawler(time_window_hours=24)
            self.mock_bird_wrapper = self.crawler.bird_wrapper
    
    def test_extract_username_from_url(self):
        """æµ‹è¯•ä»URLæå–ç”¨æˆ·å"""
        valid_urls = [
            ("https://x.com/elonmusk", "elonmusk"),
            ("https://twitter.com/jack", "jack"),
            ("https://x.com/test_user_123", "test_user_123")
        ]
        
        for url, expected_username in valid_urls:
            username = self.crawler._extract_username_from_url(url)
            assert username == expected_username
    
    def test_extract_username_invalid_url(self):
        """æµ‹è¯•ä»æ— æ•ˆURLæå–ç”¨æˆ·å"""
        invalid_urls = [
            "https://x.com/i/lists/123",  # ç‰¹æ®Šè·¯å¾„
            "https://x.com/home",         # ç‰¹æ®Šè·¯å¾„
            "invalid_url",
            ""
        ]
        
        for url in invalid_urls:
            username = self.crawler._extract_username_from_url(url)
            assert username is None
    
    def test_crawl_timeline_with_url(self):
        """æµ‹è¯•ä½¿ç”¨URLçˆ¬å–ç”¨æˆ·æ—¶é—´çº¿"""
        timeline_url = "https://x.com/elonmusk"
        
        # æ¨¡æ‹Ÿbirdå·¥å…·è¿”å›æˆåŠŸç»“æœ
        mock_result = BirdResult(
            success=True,
            output='[{"id": "456", "text": "æ—¶é—´çº¿æ¨æ–‡", "created_at": "Wed Oct 10 20:19:24 +0000 2018", "user": {"screen_name": "elonmusk"}}]',
            error="",
            exit_code=0,
            execution_time=2.0,
            command=["bird", "timeline", "--user", "elonmusk"]
        )
        
        self.mock_bird_wrapper.fetch_user_timeline.return_value = mock_result
        self.mock_bird_wrapper.parse_tweet_data.return_value = [
            {
                "id": "456",
                "text": "æ—¶é—´çº¿æ¨æ–‡",
                "created_at": "Wed Oct 10 20:19:24 +0000 2018",
                "user": {"screen_name": "elonmusk"}
            }
        ]
        
        self.crawler.authenticated = True
        
        result = self.crawler.crawl_timeline(timeline_url)
        
        assert isinstance(result, list)
        self.mock_bird_wrapper.fetch_user_timeline.assert_called_once_with("elonmusk", count=100)
    
    def test_crawl_timeline_without_url(self):
        """æµ‹è¯•ä¸ä½¿ç”¨URLçˆ¬å–ä¸»æ—¶é—´çº¿"""
        # æ¨¡æ‹Ÿbirdå·¥å…·è¿”å›æˆåŠŸç»“æœ
        mock_result = BirdResult(
            success=True,
            output='[]',
            error="",
            exit_code=0,
            execution_time=1.0,
            command=["bird", "timeline", "--user", "home"]
        )
        
        self.mock_bird_wrapper.fetch_user_timeline.return_value = mock_result
        self.mock_bird_wrapper.parse_tweet_data.return_value = []
        
        self.crawler.authenticated = True
        
        result = self.crawler.crawl_timeline()
        
        assert isinstance(result, list)
        self.mock_bird_wrapper.fetch_user_timeline.assert_called_once_with("home", count=100)
    
    def test_crawl_timeline_invalid_url(self):
        """æµ‹è¯•çˆ¬å–æ— æ•ˆæ—¶é—´çº¿URL"""
        invalid_url = "https://x.com/i/invalid"
        
        with pytest.raises(CrawlerError, match="æ— æ•ˆçš„æ—¶é—´çº¿URL"):
            self.crawler.crawl_timeline(invalid_url)


class TestXCrawlerContentParsing:
    """Xçˆ¬å–å™¨å†…å®¹è§£ææµ‹è¯•"""
    
    def setup_method(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        with patch('crypto_news_analyzer.crawlers.x_crawler.BirdWrapper') as mock_bird_wrapper:
            mock_wrapper = Mock()
            mock_wrapper.test_connection.return_value = True
            mock_bird_wrapper.return_value = mock_wrapper
            
            self.crawler = XCrawler(time_window_hours=24)
    
    def test_parse_tweet_valid_data(self):
        """æµ‹è¯•è§£ææœ‰æ•ˆçš„æ¨æ–‡æ•°æ®"""
        tweet_data = {
            "id": "1234567890123456789",
            "text": "è¿™æ˜¯ä¸€æ¡æµ‹è¯•æ¨æ–‡ #crypto #bitcoin",
            "created_at": "Wed Oct 10 20:19:24 +0000 2018",
            "user": {
                "screen_name": "test_user",
                "name": "Test User"
            }
        }
        
        result = self.crawler.parse_tweet(tweet_data)
        
        assert isinstance(result, ContentItem)
        assert result.content == tweet_data["text"]
        assert "test_user" in result.title
        assert result.url == "https://x.com/test_user/status/1234567890123456789"
        assert result.source_name == "X/Twitter"
        assert result.source_type == "x"
        assert isinstance(result.publish_time, datetime)
    
    def test_parse_tweet_missing_fields(self):
        """æµ‹è¯•è§£æç¼ºå°‘å­—æ®µçš„æ¨æ–‡æ•°æ®"""
        incomplete_tweet_data = {
            "id": "1234567890123456789",
            "text": "æµ‹è¯•æ¨æ–‡",
            # ç¼ºå°‘created_atå’Œuserå­—æ®µ
        }
        
        # åº”è¯¥èƒ½å¤Ÿè§£æï¼Œä½†ä¼šä½¿ç”¨é»˜è®¤å€¼
        result = self.crawler.parse_tweet(incomplete_tweet_data)
        
        # éªŒè¯åŸºæœ¬å­—æ®µå­˜åœ¨
        assert isinstance(result, ContentItem)
        assert result.content == "æµ‹è¯•æ¨æ–‡"
        assert result.source_name == "X/Twitter"
        assert result.source_type == "x"
    
    def test_parse_twitter_time_valid_formats(self):
        """æµ‹è¯•è§£æå„ç§æœ‰æ•ˆçš„Twitteræ—¶é—´æ ¼å¼"""
        valid_time_formats = [
            ("Wed Oct 10 20:19:24 +0000 2018", datetime(2018, 10, 10, 20, 19, 24)),
            ("2018-10-10T20:19:24.000Z", datetime(2018, 10, 10, 20, 19, 24)),
            ("2018-10-10T20:19:24Z", datetime(2018, 10, 10, 20, 19, 24)),
            ("2018-10-10 20:19:24", datetime(2018, 10, 10, 20, 19, 24))
        ]
        
        for time_str, expected_dt in valid_time_formats:
            result = self.crawler._parse_twitter_time(time_str)
            assert isinstance(result, datetime)
            # å…è®¸ä¸€å®šçš„æ—¶é—´è¯¯å·®ï¼ˆå› ä¸ºæ—¶åŒºå¤„ç†ï¼‰
            time_diff = abs((result - expected_dt).total_seconds())
            assert time_diff < 86400  # 24å°æ—¶å†…çš„è¯¯å·®ï¼ˆè€ƒè™‘æ—¶åŒºè½¬æ¢ï¼‰
    
    def test_parse_twitter_time_invalid_format(self):
        """æµ‹è¯•è§£ææ— æ•ˆçš„Twitteræ—¶é—´æ ¼å¼"""
        invalid_time_str = "invalid_time_format"
        
        # åº”è¯¥è¿”å›å½“å‰æ—¶é—´ä½œä¸ºfallback
        result = self.crawler._parse_twitter_time(invalid_time_str)
        
        assert isinstance(result, datetime)
        # éªŒè¯è¿”å›çš„æ—¶é—´æ¥è¿‘å½“å‰æ—¶é—´
        time_diff = abs((datetime.now() - result).total_seconds())
        assert time_diff < 60  # 1åˆ†é’Ÿå†…çš„è¯¯å·®
    
    def test_parse_twitter_time_empty_string(self):
        """æµ‹è¯•è§£æç©ºæ—¶é—´å­—ç¬¦ä¸²"""
        result = self.crawler._parse_twitter_time("")
        
        assert isinstance(result, datetime)
        # åº”è¯¥è¿”å›å½“å‰æ—¶é—´
        time_diff = abs((datetime.now() - result).total_seconds())
        assert time_diff < 60
    
    def test_is_within_time_window(self):
        """æµ‹è¯•æ—¶é—´çª—å£æ£€æŸ¥"""
        now = datetime.now()
        
        # åœ¨æ—¶é—´çª—å£å†…çš„æ—¶é—´
        recent_time = now - timedelta(hours=12)
        assert self.crawler.is_within_time_window(recent_time) == True
        
        # è¶…å‡ºæ—¶é—´çª—å£çš„æ—¶é—´
        old_time = now - timedelta(hours=48)
        assert self.crawler.is_within_time_window(old_time) == False
        
        # è¾¹ç•Œæƒ…å†µ - ç¨å¾®åœ¨æ—¶é—´çª—å£å†…
        boundary_time = now - timedelta(hours=23, minutes=59)
        assert self.crawler.is_within_time_window(boundary_time) == True


class TestXCrawlerBatchOperations:
    """Xçˆ¬å–å™¨æ‰¹é‡æ“ä½œæµ‹è¯•"""
    
    def setup_method(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        with patch('crypto_news_analyzer.crawlers.x_crawler.BirdWrapper') as mock_bird_wrapper:
            mock_wrapper = Mock()
            mock_wrapper.test_connection.return_value = True
            mock_bird_wrapper.return_value = mock_wrapper
            
            self.crawler = XCrawler(time_window_hours=24)
            self.mock_bird_wrapper = self.crawler.bird_wrapper
    
    def test_crawl_all_sources_empty_list(self):
        """æµ‹è¯•ç©ºæ•°æ®æºåˆ—è¡¨"""
        results = self.crawler.crawl_all_sources([])
        
        assert results == []
    
    def test_crawl_all_sources_mixed_types(self):
        """æµ‹è¯•æ··åˆç±»å‹çš„æ•°æ®æº"""
        sources = [
            XSource(name="æµ‹è¯•åˆ—è¡¨", url="https://x.com/i/lists/1111111111", type="list"),
            XSource(name="æµ‹è¯•æ—¶é—´çº¿", url="https://x.com/elonmusk", type="timeline")
        ]
        
        # æ¨¡æ‹ŸæˆåŠŸçš„birdå·¥å…·è°ƒç”¨
        success_result = BirdResult(
            success=True,
            output='[]',
            error="",
            exit_code=0,
            execution_time=1.0,
            command=["bird"]
        )
        
        self.mock_bird_wrapper.fetch_list_tweets.return_value = success_result
        self.mock_bird_wrapper.fetch_user_timeline.return_value = success_result
        self.mock_bird_wrapper.parse_tweet_data.return_value = []
        
        self.crawler.authenticated = True
        
        with patch('time.sleep'):  # è·³è¿‡å»¶è¿Ÿ
            results = self.crawler.crawl_all_sources(sources)
        
        assert len(results) == 2
        assert all(r.status == "success" for r in results)
        
        # éªŒè¯ä¸åŒç±»å‹çš„è°ƒç”¨
        self.mock_bird_wrapper.fetch_list_tweets.assert_called_once()
        self.mock_bird_wrapper.fetch_user_timeline.assert_called_once()
    
    def test_crawl_all_sources_error_isolation(self):
        """æµ‹è¯•å¤šä¸ªæ•°æ®æºæ—¶çš„é”™è¯¯éš”ç¦»"""
        sources = [
            XSource(name="æˆåŠŸæº", url="https://x.com/i/lists/1111111111", type="list"),
            XSource(name="å¤±è´¥æº", url="https://x.com/i/lists/2222222222", type="list")
        ]
        
        # ç¬¬ä¸€ä¸ªè°ƒç”¨æˆåŠŸï¼Œç¬¬äºŒä¸ªå¤±è´¥
        success_result = BirdResult(
            success=True,
            output='[]',
            error="",
            exit_code=0,
            execution_time=1.0,
            command=["bird"]
        )
        
        failure_result = BirdResult(
            success=False,
            output="",
            error="è®¤è¯å¤±è´¥",
            exit_code=1,
            execution_time=0.5,
            command=["bird"]
        )
        
        self.mock_bird_wrapper.fetch_list_tweets.side_effect = [success_result, failure_result]
        self.mock_bird_wrapper.parse_tweet_data.return_value = []
        
        self.crawler.authenticated = True
        
        with patch('time.sleep'):
            results = self.crawler.crawl_all_sources(sources)
        
        assert len(results) == 2
        assert results[0].status == "success"
        assert results[1].status == "error"
        assert "è®¤è¯å¤±è´¥" in results[1].error_message
    
    def test_crawl_all_sources_unsupported_type(self):
        """æµ‹è¯•ä¸æ”¯æŒçš„æ•°æ®æºç±»å‹"""
        # åˆ›å»ºä¸€ä¸ªæœ‰æ•ˆçš„XSourceï¼Œç„¶åæ‰‹åŠ¨ä¿®æ”¹typeæ¥ç»•è¿‡éªŒè¯
        source = XSource(name="æµ‹è¯•æº", url="https://x.com/test", type="list")
        source.type = "invalid_type"  # æ‰‹åŠ¨ä¿®æ”¹ä¸ºæ— æ•ˆç±»å‹
        
        sources = [source]
        
        self.crawler.authenticated = True
        
        results = self.crawler.crawl_all_sources(sources)
        
        assert len(results) == 1
        assert results[0].status == "error"
        assert "ä¸æ”¯æŒçš„Xæºç±»å‹" in results[0].error_message


class TestXCrawlerDiagnostics:
    """Xçˆ¬å–å™¨è¯Šæ–­åŠŸèƒ½æµ‹è¯•"""
    
    def setup_method(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        with patch('crypto_news_analyzer.crawlers.x_crawler.BirdWrapper') as mock_bird_wrapper:
            mock_wrapper = Mock()
            mock_wrapper.test_connection.return_value = True
            mock_bird_wrapper.return_value = mock_wrapper
            
            self.crawler = XCrawler(time_window_hours=24)
            self.mock_bird_wrapper = self.crawler.bird_wrapper
    
    def test_get_diagnostic_info_success(self):
        """æµ‹è¯•è·å–è¯Šæ–­ä¿¡æ¯æˆåŠŸ"""
        # æ¨¡æ‹Ÿbird wrapperè¯Šæ–­ä¿¡æ¯
        mock_diagnostic = {
            "config": {"executable_path": "bird", "timeout_seconds": 300},
            "dependency_status": {"available": True, "version": "1.0.0"},
            "connection_test": True
        }
        
        self.mock_bird_wrapper.get_diagnostic_info.return_value = mock_diagnostic
        
        result = self.crawler.get_diagnostic_info()
        
        assert "time_window_hours" in result
        assert result["time_window_hours"] == 24
        assert "authenticated" in result
        assert "bird_wrapper_info" in result
        assert result["bird_wrapper_info"] == mock_diagnostic
    
    def test_get_diagnostic_info_bird_wrapper_error(self):
        """æµ‹è¯•bird wrapperè¯Šæ–­ä¿¡æ¯è·å–å¤±è´¥"""
        self.mock_bird_wrapper.get_diagnostic_info.side_effect = Exception("è¯Šæ–­å¤±è´¥")
        
        result = self.crawler.get_diagnostic_info()
        
        assert "time_window_hours" in result
        assert "bird_wrapper_error" in result
        assert result["bird_wrapper_error"] == "è¯Šæ–­å¤±è´¥"
    
    def test_cleanup(self):
        """æµ‹è¯•èµ„æºæ¸…ç†"""
        # cleanupæ–¹æ³•åº”è¯¥æ­£å¸¸æ‰§è¡Œè€Œä¸æŠ›å‡ºå¼‚å¸¸
        self.crawler.cleanup()
        
        # éªŒè¯æ²¡æœ‰å¼‚å¸¸æŠ›å‡º
        assert True


class TestXCrawlerBirdToolIntegration:
    """Xçˆ¬å–å™¨ä¸Birdå·¥å…·é›†æˆæµ‹è¯• - ä¸“é—¨æµ‹è¯•birdå·¥å…·è°ƒç”¨å’Œé”™è¯¯å¤„ç†"""
    
    def setup_method(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        with patch('crypto_news_analyzer.crawlers.x_crawler.BirdWrapper') as mock_bird_wrapper:
            mock_wrapper = Mock()
            mock_wrapper.test_connection.return_value = True
            mock_bird_wrapper.return_value = mock_wrapper
            
            self.crawler = XCrawler(time_window_hours=24)
            self.mock_bird_wrapper = self.crawler.bird_wrapper
    
    def test_bird_tool_command_construction(self):
        """æµ‹è¯•birdå·¥å…·å‘½ä»¤æ„å»º"""
        list_url = "https://x.com/i/lists/1234567890"
        
        # æ¨¡æ‹ŸæˆåŠŸçš„birdå·¥å…·è°ƒç”¨
        mock_result = BirdResult(
            success=True,
            output='[]',
            error="",
            exit_code=0,
            execution_time=1.0,
            command=["bird", "list-timeline", "1234567890", "--json", "--count", "100"]
        )
        
        self.mock_bird_wrapper.fetch_list_tweets.return_value = mock_result
        self.mock_bird_wrapper.parse_tweet_data.return_value = []
        self.crawler.authenticated = True
        
        self.crawler.crawl_list(list_url)
        
        # éªŒè¯birdå·¥å…·è¢«æ­£ç¡®è°ƒç”¨
        self.mock_bird_wrapper.fetch_list_tweets.assert_called_once_with("1234567890", count=100)
    
    def test_bird_tool_authentication_error_handling(self):
        """æµ‹è¯•birdå·¥å…·è®¤è¯é”™è¯¯å¤„ç†"""
        list_url = "https://x.com/i/lists/1234567890"
        
        # æ¨¡æ‹Ÿè®¤è¯é”™è¯¯
        mock_result = BirdResult(
            success=False,
            output="",
            error="Authentication failed: Invalid credentials",
            exit_code=401,
            execution_time=0.5,
            command=["bird", "list-timeline", "1234567890"]
        )
        
        self.mock_bird_wrapper.fetch_list_tweets.return_value = mock_result
        self.crawler.authenticated = True
        
        with pytest.raises(CrawlerError, match="Birdå·¥å…·è·å–åˆ—è¡¨æ¨æ–‡å¤±è´¥"):
            self.crawler.crawl_list(list_url)
    
    def test_bird_tool_network_error_handling(self):
        """æµ‹è¯•birdå·¥å…·ç½‘ç»œé”™è¯¯å¤„ç†"""
        timeline_url = "https://x.com/elonmusk"
        
        # æ¨¡æ‹Ÿç½‘ç»œé”™è¯¯
        mock_result = BirdResult(
            success=False,
            output="",
            error="Network error: Connection timeout",
            exit_code=1,
            execution_time=30.0,
            command=["bird", "user-tweets", "elonmusk"]
        )
        
        self.mock_bird_wrapper.fetch_user_timeline.return_value = mock_result
        self.crawler.authenticated = True
        
        with pytest.raises(CrawlerError, match="Birdå·¥å…·è·å–æ—¶é—´çº¿æ¨æ–‡å¤±è´¥"):
            self.crawler.crawl_timeline(timeline_url)
    
    def test_bird_tool_rate_limit_error_handling(self):
        """æµ‹è¯•birdå·¥å…·é€Ÿç‡é™åˆ¶é”™è¯¯å¤„ç†"""
        list_url = "https://x.com/i/lists/1234567890"
        
        # æ¨¡æ‹Ÿé€Ÿç‡é™åˆ¶é”™è¯¯
        mock_result = BirdResult(
            success=False,
            output="",
            error="Rate limit exceeded. Please wait before making more requests.",
            exit_code=429,
            execution_time=1.0,
            command=["bird", "list-timeline", "1234567890"]
        )
        
        self.mock_bird_wrapper.fetch_list_tweets.return_value = mock_result
        self.crawler.authenticated = True
        
        with pytest.raises(CrawlerError, match="Birdå·¥å…·è·å–åˆ—è¡¨æ¨æ–‡å¤±è´¥"):
            self.crawler.crawl_list(list_url)
    
    def test_bird_tool_malformed_output_handling(self):
        """æµ‹è¯•birdå·¥å…·è¾“å‡ºæ ¼å¼é”™è¯¯å¤„ç†"""
        list_url = "https://x.com/i/lists/1234567890"
        
        # æ¨¡æ‹ŸæˆåŠŸä½†è¾“å‡ºæ ¼å¼é”™è¯¯
        mock_result = BirdResult(
            success=True,
            output="Invalid JSON output {malformed",
            error="",
            exit_code=0,
            execution_time=1.0,
            command=["bird", "list-timeline", "1234567890"]
        )
        
        self.mock_bird_wrapper.fetch_list_tweets.return_value = mock_result
        self.mock_bird_wrapper.parse_tweet_data.return_value = []  # è§£æå¤±è´¥è¿”å›ç©ºåˆ—è¡¨
        self.crawler.authenticated = True
        
        # åº”è¯¥èƒ½å¤Ÿå¤„ç†è§£æå¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
        result = self.crawler.crawl_list(list_url)
        assert result == []
    
    def test_bird_tool_partial_success_handling(self):
        """æµ‹è¯•birdå·¥å…·éƒ¨åˆ†æˆåŠŸçš„å¤„ç†"""
        list_url = "https://x.com/i/lists/1234567890"
        
        # æ¨¡æ‹Ÿéƒ¨åˆ†æˆåŠŸï¼ˆæœ‰äº›æ¨æ–‡è§£æå¤±è´¥ï¼‰
        mock_result = BirdResult(
            success=True,
            output='[{"id": "123", "text": "valid tweet"}, {"invalid": "data"}]',
            error="",
            exit_code=0,
            execution_time=1.0,
            command=["bird", "list-timeline", "1234567890"]
        )
        
        # æ¨¡æ‹Ÿè§£ææ—¶åªè¿”å›æœ‰æ•ˆçš„æ¨æ–‡
        self.mock_bird_wrapper.fetch_list_tweets.return_value = mock_result
        self.mock_bird_wrapper.parse_tweet_data.return_value = [
            {
                "id": "123",
                "text": "valid tweet",
                "created_at": "Wed Oct 10 20:19:24 +0000 2018",
                "user": {"screen_name": "test_user"}
            }
        ]
        self.crawler.authenticated = True
        
        result = self.crawler.crawl_list(list_url)
        
        # åº”è¯¥åªè¿”å›æœ‰æ•ˆè§£æçš„æ¨æ–‡
        assert len(result) >= 0  # å¯èƒ½å› ä¸ºæ—¶é—´çª—å£è¿‡æ»¤è€Œä¸ºç©º


class TestXCrawlerOutputParsing:
    """Xçˆ¬å–å™¨è¾“å‡ºè§£æå’Œæ•°æ®æå–é€»è¾‘æµ‹è¯•"""
    
    def setup_method(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        with patch('crypto_news_analyzer.crawlers.x_crawler.BirdWrapper') as mock_bird_wrapper:
            mock_wrapper = Mock()
            mock_wrapper.test_connection.return_value = True
            mock_bird_wrapper.return_value = mock_wrapper
            
            self.crawler = XCrawler(time_window_hours=24)
    
    def test_parse_tweet_with_special_characters(self):
        """æµ‹è¯•è§£æåŒ…å«ç‰¹æ®Šå­—ç¬¦çš„æ¨æ–‡"""
        tweet_data = {
            "id": "1234567890123456789",
            "text": "æµ‹è¯•æ¨æ–‡ ğŸš€ #crypto $BTC @elonmusk https://t.co/abc123 \næ¢è¡Œæµ‹è¯•",
            "created_at": "Wed Oct 10 20:19:24 +0000 2018",
            "user": {
                "screen_name": "test_user",
                "name": "Test User æµ‹è¯•"
            }
        }
        
        result = self.crawler.parse_tweet(tweet_data)
        
        assert isinstance(result, ContentItem)
        assert "ğŸš€" in result.content
        assert "#crypto" in result.content
        assert "$BTC" in result.content
        assert "@elonmusk" in result.content
        assert "https://t.co/abc123" in result.content
        assert "\n" in result.content
    
    def test_parse_tweet_with_minimal_data(self):
        """æµ‹è¯•è§£ææœ€å°æ•°æ®é›†çš„æ¨æ–‡"""
        tweet_data = {
            "id": "123",
            "text": "minimal tweet"
        }
        
        result = self.crawler.parse_tweet(tweet_data)
        
        assert isinstance(result, ContentItem)
        assert result.content == "minimal tweet"
        assert result.source_name == "X/Twitter"
        assert result.source_type == "x"
        assert "unknown" in result.title
    
    def test_parse_tweet_with_empty_fields(self):
        """æµ‹è¯•è§£æç©ºå­—æ®µçš„æ¨æ–‡"""
        tweet_data = {
            "id": "",
            "text": "",
            "created_at": "",
            "user": {
                "screen_name": "",
                "name": ""
            }
        }
        
        # ç©ºå†…å®¹åº”è¯¥æŠ›å‡ºCrawlerError
        with pytest.raises(CrawlerError, match="è§£ææ¨æ–‡å¤±è´¥"):
            self.crawler.parse_tweet(tweet_data)
    
    def test_parse_tweet_with_nested_user_data(self):
        """æµ‹è¯•è§£æåµŒå¥—ç”¨æˆ·æ•°æ®çš„æ¨æ–‡"""
        tweet_data = {
            "id": "1234567890123456789",
            "text": "nested user data test",
            "created_at": "Wed Oct 10 20:19:24 +0000 2018",
            "user": {
                "screen_name": "test_user",
                "name": "Test User",
                "id": "987654321",
                "verified": True,
                "followers_count": 1000,
                "profile_image_url": "https://example.com/image.jpg"
            }
        }
        
        result = self.crawler.parse_tweet(tweet_data)
        
        assert isinstance(result, ContentItem)
        assert "test_user" in result.title
        assert "test_user" in result.url
        assert result.content == "nested user data test"
    
    def test_parse_twitter_time_edge_cases(self):
        """æµ‹è¯•Twitteræ—¶é—´è§£æçš„è¾¹ç•Œæƒ…å†µ"""
        # æµ‹è¯•å„ç§è¾¹ç•Œæ—¶é—´æ ¼å¼
        edge_cases = [
            ("", datetime.now()),  # ç©ºå­—ç¬¦ä¸²
            ("invalid_format", datetime.now()),  # æ— æ•ˆæ ¼å¼
            ("2018-02-29T12:00:00Z", None),  # æ— æ•ˆæ—¥æœŸï¼ˆ2018å¹´ä¸æ˜¯é—°å¹´ï¼‰
            ("2020-02-29T12:00:00Z", datetime(2020, 2, 29, 12, 0, 0)),  # æœ‰æ•ˆé—°å¹´æ—¥æœŸ
            ("Wed Dec 31 23:59:59 +0000 2025", datetime(2025, 12, 31, 23, 59, 59)),  # å¹´æœ«
            ("Mon Jan 01 00:00:00 +0000 2024", datetime(2024, 1, 1, 0, 0, 0)),  # å¹´åˆ
        ]
        
        for time_str, expected in edge_cases:
            result = self.crawler._parse_twitter_time(time_str)
            assert isinstance(result, datetime)
            
            if expected and time_str not in ["", "invalid_format", "2018-02-29T12:00:00Z"]:
                # å…è®¸æ—¶åŒºè½¬æ¢çš„è¯¯å·®
                time_diff = abs((result - expected).total_seconds())
                assert time_diff < 86400  # 24å°æ—¶å†…çš„è¯¯å·®ï¼ˆè€ƒè™‘æ—¶åŒºï¼‰
    
    def test_url_extraction_edge_cases(self):
        """æµ‹è¯•URLæå–çš„è¾¹ç•Œæƒ…å†µ"""
        # æµ‹è¯•åˆ—è¡¨IDæå–
        list_url_cases = [
            ("https://x.com/i/lists/1234567890123456789", "1234567890123456789"),
            ("https://twitter.com/i/lists/987654321", "987654321"),
            ("https://x.com/i/lists/", None),  # ç©ºID
            ("https://x.com/user/profile", None),  # éåˆ—è¡¨URL
            ("invalid_url", None),  # å®Œå…¨æ— æ•ˆçš„URL
            ("", None),  # ç©ºå­—ç¬¦ä¸²
        ]
        
        for url, expected_id in list_url_cases:
            result = self.crawler._extract_list_id_from_url(url)
            assert result == expected_id
        
        # æµ‹è¯•ç”¨æˆ·åæå–
        username_cases = [
            ("https://x.com/elonmusk", "elonmusk"),
            ("https://twitter.com/jack", "jack"),
            ("https://x.com/user_with_underscore", "user_with_underscore"),
            ("https://x.com/i/lists/123", None),  # ç‰¹æ®Šè·¯å¾„
            ("https://x.com/home", None),  # ç‰¹æ®Šè·¯å¾„
            ("https://x.com/", None),  # ç©ºç”¨æˆ·å
            ("invalid_url", None),  # æ— æ•ˆURL
        ]
        
        for url, expected_username in username_cases:
            result = self.crawler._extract_username_from_url(url)
            assert result == expected_username
    
    def test_time_window_filtering_precision(self):
        """æµ‹è¯•æ—¶é—´çª—å£è¿‡æ»¤çš„ç²¾ç¡®æ€§"""
        now = datetime.now()
        
        # æµ‹è¯•ç²¾ç¡®è¾¹ç•Œ
        test_cases = [
            (now - timedelta(hours=23, minutes=59, seconds=59), True),  # åˆšå¥½åœ¨çª—å£å†…
            (now - timedelta(hours=24, minutes=0, seconds=1), False),   # åˆšå¥½è¶…å‡ºçª—å£
            (now - timedelta(hours=12), True),                         # æ˜æ˜¾åœ¨çª—å£å†…
            (now - timedelta(hours=48), False),                        # æ˜æ˜¾è¶…å‡ºçª—å£
            (now + timedelta(hours=1), True),                          # æœªæ¥æ—¶é—´ï¼ˆåº”è¯¥åœ¨çª—å£å†…ï¼‰
        ]
        
        for test_time, expected in test_cases:
            result = self.crawler.is_within_time_window(test_time)
            assert result == expected, f"æ—¶é—´ {test_time} çš„è¿‡æ»¤ç»“æœåº”è¯¥æ˜¯ {expected}"


class TestXCrawlerDependencyValidation:
    """Xçˆ¬å–å™¨ä¾èµ–æ£€æŸ¥å’Œé…ç½®éªŒè¯æµ‹è¯•"""
    
    def test_bird_config_validation(self):
        """æµ‹è¯•Birdé…ç½®éªŒè¯"""
        # æµ‹è¯•æœ‰æ•ˆé…ç½®
        valid_config = BirdConfig(
            executable_path="bird",
            timeout_seconds=300,
            max_retries=3,
            output_format="json"
        )
        
        with patch('crypto_news_analyzer.crawlers.x_crawler.BirdWrapper') as mock_bird_wrapper:
            mock_wrapper = Mock()
            mock_wrapper.test_connection.return_value = True
            mock_bird_wrapper.return_value = mock_wrapper
            
            crawler = XCrawler(time_window_hours=24, bird_config=valid_config)
            assert crawler.time_window_hours == 24
    
    def test_bird_dependency_check_failure(self):
        """æµ‹è¯•Birdä¾èµ–æ£€æŸ¥å¤±è´¥"""
        with patch('crypto_news_analyzer.crawlers.x_crawler.BirdWrapper') as mock_bird_wrapper:
            mock_bird_wrapper.side_effect = RuntimeError("Birdå·¥å…·ä¸å¯ç”¨")
            
            with pytest.raises(CrawlerError, match="Birdå·¥å…·åˆå§‹åŒ–å¤±è´¥"):
                XCrawler(time_window_hours=24)
    
    def test_authentication_validation(self):
        """æµ‹è¯•è®¤è¯éªŒè¯"""
        with patch('crypto_news_analyzer.crawlers.x_crawler.BirdWrapper') as mock_bird_wrapper:
            mock_wrapper = Mock()
            mock_wrapper.test_connection.return_value = False  # è®¤è¯å¤±è´¥
            mock_bird_wrapper.return_value = mock_wrapper
            
            crawler = XCrawler(time_window_hours=24)
            
            # åˆå§‹è®¤è¯çŠ¶æ€åº”è¯¥æ˜¯False
            assert crawler.authenticated == False
            
            # æ‰‹åŠ¨è®¤è¯ä¹Ÿåº”è¯¥å¤±è´¥
            result = crawler.authenticate()
            assert result == False
    
    def test_diagnostic_info_completeness(self):
        """æµ‹è¯•è¯Šæ–­ä¿¡æ¯å®Œæ•´æ€§"""
        with patch('crypto_news_analyzer.crawlers.x_crawler.BirdWrapper') as mock_bird_wrapper:
            mock_wrapper = Mock()
            mock_wrapper.test_connection.return_value = True
            mock_wrapper.get_diagnostic_info.return_value = {
                "config": {"executable_path": "bird"},
                "dependency_status": {"available": True},
                "connection_test": True
            }
            mock_bird_wrapper.return_value = mock_wrapper
            
            crawler = XCrawler(time_window_hours=24)
            diagnostic = crawler.get_diagnostic_info()
            
            # éªŒè¯è¯Šæ–­ä¿¡æ¯åŒ…å«å¿…è¦å­—æ®µ
            assert "time_window_hours" in diagnostic
            assert "authenticated" in diagnostic
            assert "bird_wrapper_info" in diagnostic
            
            assert diagnostic["time_window_hours"] == 24
            assert isinstance(diagnostic["authenticated"], bool)
            assert isinstance(diagnostic["bird_wrapper_info"], dict)
    
    def test_error_recovery_mechanisms(self):
        """æµ‹è¯•é”™è¯¯æ¢å¤æœºåˆ¶"""
        with patch('crypto_news_analyzer.crawlers.x_crawler.BirdWrapper') as mock_bird_wrapper:
            mock_wrapper = Mock()
            mock_wrapper.test_connection.return_value = True
            mock_bird_wrapper.return_value = mock_wrapper
            
            crawler = XCrawler(time_window_hours=24)
            
            # æµ‹è¯•åœ¨birdå·¥å…·è°ƒç”¨å¤±è´¥æ—¶çš„æ¢å¤
            sources = [
                XSource(name="å¤±è´¥æº", url="https://x.com/i/lists/1111111111", type="list"),
                XSource(name="æˆåŠŸæº", url="https://x.com/i/lists/2222222222", type="list")
            ]
            
            # ç¬¬ä¸€ä¸ªè°ƒç”¨å¤±è´¥ï¼Œç¬¬äºŒä¸ªæˆåŠŸ
            failure_result = BirdResult(
                success=False,
                output="",
                error="ç½‘ç»œé”™è¯¯",
                exit_code=1,
                execution_time=0.5,
                command=["bird"]
            )
            
            success_result = BirdResult(
                success=True,
                output='[]',
                error="",
                exit_code=0,
                execution_time=1.0,
                command=["bird"]
            )
            
            mock_wrapper.fetch_list_tweets.side_effect = [failure_result, success_result]
            mock_wrapper.parse_tweet_data.return_value = []
            
            with patch('time.sleep'):  # è·³è¿‡å»¶è¿Ÿ
                results = crawler.crawl_all_sources(sources)
            
            # éªŒè¯é”™è¯¯éš”ç¦»ï¼šç¬¬ä¸€ä¸ªå¤±è´¥ï¼Œç¬¬äºŒä¸ªæˆåŠŸ
            assert len(results) == 2
            assert results[0].status == "error"
            assert results[1].status == "success"
            assert "ç½‘ç»œé”™è¯¯" in results[0].error_message
    
    def test_configuration_parameter_validation(self):
        """æµ‹è¯•é…ç½®å‚æ•°éªŒè¯"""
        # æµ‹è¯•æ— æ•ˆçš„æ—¶é—´çª—å£å‚æ•°
        with patch('crypto_news_analyzer.crawlers.x_crawler.BirdWrapper') as mock_bird_wrapper:
            mock_wrapper = Mock()
            mock_wrapper.test_connection.return_value = True
            mock_bird_wrapper.return_value = mock_wrapper
            
            # è´Ÿæ•°æ—¶é—´çª—å£
            crawler = XCrawler(time_window_hours=-1)
            assert crawler.time_window_hours == -1  # åº”è¯¥æ¥å—ä½†åœ¨ä½¿ç”¨æ—¶å¤„ç†
            
            # é›¶æ—¶é—´çª—å£
            crawler = XCrawler(time_window_hours=0)
            assert crawler.time_window_hours == 0
            
            # æå¤§æ—¶é—´çª—å£
            crawler = XCrawler(time_window_hours=8760)  # ä¸€å¹´
            assert crawler.time_window_hours == 8760


if __name__ == "__main__":
    # è¿è¡Œå•å…ƒæµ‹è¯•
    pytest.main([__file__, "-v", "--tb=short"])