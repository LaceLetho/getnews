"""
LLMå†…å®¹åˆ†ç±»ä¸€è‡´æ€§å±æ€§æµ‹è¯•

ä½¿ç”¨Hypothesisè¿›è¡Œå±æ€§æµ‹è¯•ï¼ŒéªŒè¯LLMåˆ†æå™¨çš„å†…å®¹åˆ†ç±»ä¸€è‡´æ€§ã€‚
**åŠŸèƒ½: crypto-news-analyzer, å±æ€§ 5: å†…å®¹åˆ†ç±»ä¸€è‡´æ€§**
**éªŒè¯: éœ€æ±‚ 5.1, 5.3**
"""

import pytest
import tempfile
import os
import json
from datetime import datetime, timedelta
from pathlib import Path
from hypothesis import given, strategies as st, assume, settings
from typing import List, Dict, Any, Optional

from crypto_news_analyzer.analyzers.llm_analyzer import LLMAnalyzer, ContentClassifier
from crypto_news_analyzer.analyzers.prompt_manager import PromptManager, DynamicCategoryManager
from crypto_news_analyzer.models import ContentItem, AnalysisResult


# ç­–ç•¥å®šä¹‰ï¼šç”Ÿæˆæµ‹è¯•å†…å®¹
@st.composite
def valid_crypto_content(draw):
    """ç”Ÿæˆæœ‰æ•ˆçš„åŠ å¯†è´§å¸ç›¸å…³å†…å®¹"""
    # å®šä¹‰ä¸åŒç±»åˆ«çš„å†…å®¹æ¨¡æ¿
    content_templates = {
        "å¤§æˆ·åŠ¨å‘": [
            "å·¨é²¸åœ°å€è½¬ç§»{amount}ä¸ªETHåˆ°{exchange}äº¤æ˜“æ‰€",
            "æŸçŸ¥ååœ°å€åœ¨è¿‡å»24å°æ—¶å†…{action}{amount}ä¸ªæ¯”ç‰¹å¸",
            "å¤§æˆ·èµ„é‡‘æµ{direction}ï¼Œå•ç¬”äº¤æ˜“è¶…è¿‡{amount}ä¸‡ç¾å…ƒ",
            "MicroStrategyå®£å¸ƒ{action}æ¯”ç‰¹å¸ï¼Œæ€»æŒä»“è¾¾åˆ°{amount}ä¸ªBTC"
        ],
        "åˆ©ç‡äº‹ä»¶": [
            "ç¾è”å‚¨{official}å‘è¡¨{tone}è¨€è®ºï¼Œæš—ç¤º{direction}åˆ©ç‡æ”¿ç­–",
            "FOMCä¼šè®®çºªè¦æ˜¾ç¤º{direction}é¢„æœŸï¼Œå¸‚åœºååº”{reaction}",
            "é€šèƒ€æ•°æ®{trend}ï¼Œç¾è”å‚¨æ”¿ç­–é¢„æœŸå‘ç”Ÿ{change}",
            "é²å¨å°”åœ¨Jackson Holeä¼šè®®ä¸Šè¡¨ç¤º{statement}"
        ],
        "ç¾å›½æ”¿åºœç›‘ç®¡æ”¿ç­–": [
            "SEC{action}åŠ å¯†è´§å¸{product}ï¼Œå¸‚åœº{reaction}",
            "ç¾å›½å›½ä¼š{action}åŠ å¯†è´§å¸ç›‘ç®¡æ³•æ¡ˆ",
            "CFTCå‘å¸ƒ{type}æŒ‡å¯¼æ„è§ï¼Œæ¶‰åŠ{scope}",
            "è´¢æ”¿éƒ¨å®£å¸ƒ{policy}ï¼Œå½±å“{target}"
        ],
        "å®‰å…¨äº‹ä»¶": [
            "{protocol}åè®®é­å—{attack_type}æ”»å‡»ï¼ŒæŸå¤±{amount}ä¸‡ç¾å…ƒ",
            "å‘ç°{platform}æ™ºèƒ½åˆçº¦{vulnerability}æ¼æ´",
            "é»‘å®¢åˆ©ç”¨{method}ç›—å–{amount}ä¸ª{token}",
            "{exchange}äº¤æ˜“æ‰€æš‚åœæç°ï¼Œç–‘ä¼¼é­å—{attack}"
        ],
        "æ–°äº§å“": [
            "Vç¥æ¨èçš„æ–°{type}è§£å†³æ–¹æ¡ˆ{name}æ­£å¼ä¸Šçº¿",
            "çŸ¥åå¼€å‘è€…å‘å¸ƒåˆ›æ–°{product}ï¼Œå…·æœ‰{feature}åŠŸèƒ½",
            "{kol}ä»‹ç»äº†é©å‘½æ€§çš„{technology}é¡¹ç›®",
            "æ–°çš„{category}åè®®{name}è·å¾—{endorsement}è®¤å¯"
        ],
        "å¸‚åœºæ–°ç°è±¡": [
            "NFTå¸‚åœºå‡ºç°{trend}äº¤æ˜“æ¨¡å¼",
            "é“¾ä¸Šæ´»è·ƒåº¦{change}ï¼Œ{metric}åˆ›å†å²{record}",
            "{defi_metric}é”ä»“é‡{trend}ï¼Œè¾¾åˆ°{amount}äº¿ç¾å…ƒ",
            "åŠ å¯†è´§å¸å¸‚åœºå‡ºç°{pattern}ç°è±¡"
        ],
        "å¹¿å‘Šè½¯æ–‡": [
            "ğŸš€è¶…é«˜æ”¶ç›Šç‡{product}ï¼Œç«‹å³å‚ä¸ï¼",
            "åƒè½½éš¾é€¢çš„æœºä¼šï¼{project}æä¾›{rate}å¹´åŒ–æ”¶ç›Šç‡",
            "é™æ—¶ä¼˜æƒ ï¼{platform}æ³¨å†Œé€{bonus}",
            "ä¸è¦é”™è¿‡ï¼{token}å³å°†{event}ï¼Œé¢„æœŸ{return}"
        ],
        "ä¸€èˆ¬ä¿¡æ¯": [
            "ä»Šæ—¥åŠ å¯†è´§å¸å¸‚åœº{trend}",
            "æ¯”ç‰¹å¸ä»·æ ¼{movement}è‡³{price}ç¾å…ƒ",
            "ä»¥å¤ªåŠç½‘ç»œ{status}ï¼Œgasè´¹ç”¨{level}",
            "åŠ å¯†è´§å¸æ€»å¸‚å€¼{change}ï¼Œè¾¾åˆ°{amount}ä¸‡äº¿ç¾å…ƒ"
        ]
    }
    
    # é€‰æ‹©å†…å®¹ç±»åˆ«
    category = draw(st.sampled_from(list(content_templates.keys())))
    template = draw(st.sampled_from(content_templates[category]))
    
    # ç”Ÿæˆæ¨¡æ¿å‚æ•°
    params = {}
    if "{amount}" in template:
        params["amount"] = draw(st.integers(min_value=1000, max_value=50000))
    if "{exchange}" in template:
        params["exchange"] = draw(st.sampled_from(["Binance", "Coinbase", "Kraken", "OKX"]))
    if "{action}" in template:
        params["action"] = draw(st.sampled_from(["å¢æŒ", "å‡æŒ", "è½¬ç§»", "è´­ä¹°", "å‡ºå”®"]))
    if "{direction}" in template:
        params["direction"] = draw(st.sampled_from(["æµå…¥", "æµå‡º", "åŠ æ¯", "é™æ¯", "ä¸Šæ¶¨", "ä¸‹è·Œ"]))
    if "{official}" in template:
        params["official"] = draw(st.sampled_from(["ä¸»å¸­é²å¨å°”", "å‰¯ä¸»å¸­", "å§”å‘˜"]))
    if "{tone}" in template:
        params["tone"] = draw(st.sampled_from(["é¹°æ´¾", "é¸½æ´¾", "ä¸­æ€§"]))
    if "{reaction}" in template:
        params["reaction"] = draw(st.sampled_from(["ç§¯æ", "æ¶ˆæ", "å¹³æ·¡", "å¼ºçƒˆ"]))
    if "{trend}" in template:
        params["trend"] = draw(st.sampled_from(["ä¸Šå‡", "ä¸‹é™", "ç¨³å®š", "æ³¢åŠ¨"]))
    if "{change}" in template:
        params["change"] = draw(st.sampled_from(["å˜åŒ–", "è°ƒæ•´", "è½¬å‘", "ä¿®æ­£"]))
    if "{statement}" in template:
        params["statement"] = draw(st.sampled_from(["å°†ç»§ç»­è§‚å¯Ÿé€šèƒ€æ•°æ®", "æ”¿ç­–éœ€è¦æ›´åŠ çµæ´»", "ç»æµå‰æ™¯å­˜åœ¨ä¸ç¡®å®šæ€§"]))
    if "{product}" in template:
        params["product"] = draw(st.sampled_from(["ETF", "æœŸè´§", "è¡ç”Ÿå“", "ç°è´§"]))
    if "{type}" in template:
        params["type"] = draw(st.sampled_from(["Layer2", "DeFi", "NFT", "è·¨é“¾"]))
    if "{protocol}" in template:
        params["protocol"] = draw(st.sampled_from(["Uniswap", "Compound", "Aave", "Curve"]))
    if "{attack_type}" in template:
        params["attack_type"] = draw(st.sampled_from(["é‡å…¥", "é—ªç”µè´·", "æ²»ç†", "é¢„è¨€æœº"]))
    if "{vulnerability}" in template:
        params["vulnerability"] = draw(st.sampled_from(["é‡å…¥", "æ•´æ•°æº¢å‡º", "æƒé™", "é€»è¾‘"]))
    if "{method}" in template:
        params["method"] = draw(st.sampled_from(["é’“é±¼æ”»å‡»", "ç§é’¥æ³„éœ²", "åˆçº¦æ¼æ´", "ç¤¾ä¼šå·¥ç¨‹"]))
    if "{token}" in template:
        params["token"] = draw(st.sampled_from(["ETH", "USDC", "USDT", "DAI"]))
    if "{attack}" in template:
        params["attack"] = draw(st.sampled_from(["DDoSæ”»å‡»", "é»‘å®¢å…¥ä¾µ", "ç³»ç»Ÿæ•…éšœ"]))
    if "{name}" in template:
        params["name"] = draw(st.sampled_from(["Optimism", "Arbitrum", "Polygon", "zkSync"]))
    if "{feature}" in template:
        params["feature"] = draw(st.sampled_from(["é›¶çŸ¥è¯†è¯æ˜", "è·¨é“¾æ¡¥æ¥", "è‡ªåŠ¨åšå¸‚", "æµåŠ¨æ€§æŒ–çŸ¿"]))
    if "{kol}" in template:
        params["kol"] = draw(st.sampled_from(["Vç¥", "CZ", "SBF", "çŸ¥ååˆ†æå¸ˆ"]))
    if "{technology}" in template:
        params["technology"] = draw(st.sampled_from(["åŒºå—é“¾", "DeFi", "NFT", "å…ƒå®‡å®™"]))
    if "{category}" in template:
        params["category"] = draw(st.sampled_from(["å€Ÿè´·", "äº¤æ˜“", "ä¿é™©", "è¡ç”Ÿå“"]))
    if "{endorsement}" in template:
        params["endorsement"] = draw(st.sampled_from(["ç¤¾åŒº", "æŠ•èµ„è€…", "å¼€å‘è€…", "ç”¨æˆ·"]))
    if "{defi_metric}" in template:
        params["defi_metric"] = draw(st.sampled_from(["DeFi", "TVL", "æµåŠ¨æ€§"]))
    if "{metric}" in template:
        params["metric"] = draw(st.sampled_from(["äº¤æ˜“é‡", "åœ°å€æ•°", "å“ˆå¸Œç‡", "ç½‘ç»œè´¹ç”¨"]))
    if "{record}" in template:
        params["record"] = draw(st.sampled_from(["æ–°é«˜", "æ–°ä½", "è®°å½•"]))
    if "{pattern}" in template:
        params["pattern"] = draw(st.sampled_from(["å»ä¸­å¿ƒåŒ–", "æœºæ„åŒ–", "é›¶å”®åŒ–", "å…¨çƒåŒ–"]))
    if "{project}" in template:
        params["project"] = draw(st.sampled_from(["DeFié¡¹ç›®", "æŒ–çŸ¿é¡¹ç›®", "è´¨æŠ¼é¡¹ç›®", "æµåŠ¨æ€§é¡¹ç›®"]))
    if "{rate}" in template:
        params["rate"] = draw(st.integers(min_value=100, max_value=1000))
    if "{platform}" in template:
        params["platform"] = draw(st.sampled_from(["äº¤æ˜“å¹³å°", "DeFiå¹³å°", "å€Ÿè´·å¹³å°"]))
    if "{bonus}" in template:
        params["bonus"] = draw(st.integers(min_value=10, max_value=1000))
    if "{event}" in template:
        params["event"] = draw(st.sampled_from(["ä¸Šçº¿", "ç©ºæŠ•", "å‡åŠ", "å‡çº§"]))
    if "{return}" in template:
        params["return"] = draw(st.sampled_from(["10å€æ”¶ç›Š", "æš´æ¶¨", "ç¿»å€", "é«˜æ”¶ç›Š"]))
    if "{movement}" in template:
        params["movement"] = draw(st.sampled_from(["ä¸Šæ¶¨", "ä¸‹è·Œ", "çªç ´", "å›è°ƒ"]))
    if "{price}" in template:
        params["price"] = draw(st.integers(min_value=20000, max_value=100000))
    if "{status}" in template:
        params["status"] = draw(st.sampled_from(["æ‹¥å µ", "æ­£å¸¸", "å‡çº§", "ç»´æŠ¤"]))
    if "{level}" in template:
        params["level"] = draw(st.sampled_from(["è¾ƒé«˜", "è¾ƒä½", "æ­£å¸¸", "å¼‚å¸¸"]))
    
    # å¡«å……æ¨¡æ¿
    try:
        content = template.format(**params)
    except KeyError:
        # å¦‚æœæœ‰æœªå¤„ç†çš„å‚æ•°ï¼Œä½¿ç”¨åŸå§‹æ¨¡æ¿
        content = template
    
    # ç”Ÿæˆæ ‡é¢˜
    title_templates = [
        "ã€å¿«è®¯ã€‘{content_preview}",
        "é‡è¦æ¶ˆæ¯ï¼š{content_preview}",
        "å¸‚åœºåŠ¨æ€ï¼š{content_preview}",
        "æœ€æ–°èµ„è®¯ï¼š{content_preview}",
        "{content_preview}"
    ]
    title_template = draw(st.sampled_from(title_templates))
    content_preview = content[:20] + "..." if len(content) > 20 else content
    title = title_template.format(content_preview=content_preview)
    
    return {
        "title": title,
        "content": content,
        "expected_category": category,
        "source": draw(st.sampled_from(["RSSæº", "Xæº", "æµ‹è¯•æº"]))
    }


@st.composite
def content_item_from_crypto_content(draw):
    """ä»åŠ å¯†è´§å¸å†…å®¹ç”ŸæˆContentItem"""
    crypto_content = draw(valid_crypto_content())
    
    # ç”Ÿæˆæ—¶é—´ï¼ˆæœ€è¿‘48å°æ—¶å†…ï¼‰
    now = datetime.now()
    hours_ago = draw(st.integers(min_value=0, max_value=48))
    publish_time = now - timedelta(hours=hours_ago)
    
    # ç”Ÿæˆå”¯ä¸€URLå’ŒID
    url_id = draw(st.integers(min_value=1, max_value=999999))
    url = f"https://example.com/news/{url_id}"
    
    # ç”Ÿæˆå”¯ä¸€IDï¼ˆåŒ…å«æ—¶é—´æˆ³é¿å…é‡å¤ï¼‰
    import time
    item_id = f"test_{url_id}_{int(time.time() * 1000000) % 1000000}"
    
    content_item = ContentItem(
        id=item_id,
        title=crypto_content["title"],
        content=crypto_content["content"],
        url=url,
        publish_time=publish_time,
        source_name=crypto_content["source"],
        source_type=draw(st.sampled_from(["rss", "x", "rest_api"]))
    )
    
    return content_item, crypto_content["expected_category"]


class TestLLMContentClassificationProperties:
    """LLMå†…å®¹åˆ†ç±»ä¸€è‡´æ€§å±æ€§æµ‹è¯•"""
    
    def setup_method(self):
        """æµ‹è¯•å‰è®¾ç½®"""
        # åˆ›å»ºä¸´æ—¶ç›®å½•å’Œé…ç½®æ–‡ä»¶
        self.temp_dir = tempfile.mkdtemp()
        self.prompt_config_path = os.path.join(self.temp_dir, "analysis_prompt.json")
        
        # å¤åˆ¶é»˜è®¤é…ç½®
        default_config_path = "./prompts/analysis_prompt.json"
        if os.path.exists(default_config_path):
            with open(default_config_path, 'r', encoding='utf-8') as f:
                config_data = json.load(f)
        else:
            # å¦‚æœé»˜è®¤é…ç½®ä¸å­˜åœ¨ï¼Œåˆ›å»ºåŸºæœ¬é…ç½®
            config_data = {
                "prompt_template": "åˆ†æä»¥ä¸‹å†…å®¹ï¼š\næ ‡é¢˜ï¼š{title}\nå†…å®¹ï¼š{content}\næ¥æºï¼š{source}\n\n{categories_description}\n\n{ignore_criteria}\n\n{output_format}",
                "categories": {
                    "å¤§æˆ·åŠ¨å‘": {
                        "description": "å¤§æˆ·èµ„é‡‘æµåŠ¨å’Œæ€åº¦å˜åŒ–",
                        "criteria": ["å·¨é²¸èµ„é‡‘æµåŠ¨", "å¤§æˆ·æ€åº¦å˜åŒ–"],
                        "examples": ["å·¨é²¸è½¬ç§»ETH", "æœºæ„å¢æŒBTC"],
                        "priority": 1
                    },
                    "åˆ©ç‡äº‹ä»¶": {
                        "description": "ç¾è”å‚¨ç›¸å…³çš„åˆ©ç‡æ”¿ç­–äº‹ä»¶",
                        "criteria": ["ç¾è”å‚¨å‘è¨€", "FOMCä¼šè®®"],
                        "examples": ["é²å¨å°”è®²è¯", "åˆ©ç‡å†³è®®"],
                        "priority": 1
                    },
                    "ç¾å›½æ”¿åºœç›‘ç®¡æ”¿ç­–": {
                        "description": "ç¾å›½æ”¿åºœå¯¹åŠ å¯†è´§å¸çš„ç›‘ç®¡æ”¿ç­–å˜åŒ–",
                        "criteria": ["SECæ”¿ç­–", "ç›‘ç®¡æ‰§æ³•"],
                        "examples": ["SECæ‰¹å‡†ETF", "ç›‘ç®¡æ³•æ¡ˆ"],
                        "priority": 1
                    },
                    "å®‰å…¨äº‹ä»¶": {
                        "description": "å½±å“è¾ƒå¤§çš„å®‰å…¨ç›¸å…³äº‹ä»¶",
                        "criteria": ["é»‘å®¢æ”»å‡»", "èµ„é‡‘è¢«ç›—"],
                        "examples": ["DeFiè¢«é»‘", "äº¤æ˜“æ‰€è¢«ç›—"],
                        "priority": 1
                    },
                    "æ–°äº§å“": {
                        "description": "KOLæåŠçš„çœŸæ­£åˆ›æ–°äº§å“",
                        "criteria": ["KOLæ¨è", "åˆ›æ–°é¡¹ç›®"],
                        "examples": ["Vç¥æ¨è", "æ–°åè®®ä¸Šçº¿"],
                        "priority": 2
                    },
                    "å¸‚åœºæ–°ç°è±¡": {
                        "description": "é‡è¦çš„å¸‚åœºæ–°è¶‹åŠ¿å’Œå˜åŒ–",
                        "criteria": ["æ–°è¶‹åŠ¿", "é“¾ä¸Šæ•°æ®å¼‚å¸¸"],
                        "examples": ["NFTæ–°æ¨¡å¼", "TVLåˆ›æ–°é«˜"],
                        "priority": 2
                    }
                },
                "ignore_criteria": [
                    "å¹¿å‘Šå’Œè½¯æ–‡",
                    "é‡å¤ä¿¡æ¯",
                    "æƒ…ç»ªå‘æ³„",
                    "ç©ºæ´é¢„æµ‹",
                    "ç«‹åœºäº‰è®º"
                ],
                "output_format": "è¯·è¾“å‡ºJSONæ ¼å¼ï¼š{\"category\": \"ç±»åˆ«\", \"confidence\": 0.85, \"reasoning\": \"ç†ç”±\", \"should_ignore\": false, \"key_points\": []}",
                "llm_settings": {
                    "temperature": 0.1,
                    "max_tokens": 1000,
                    "model": "gpt-4"
                }
            }
        
        # ä¿å­˜é…ç½®æ–‡ä»¶
        with open(self.prompt_config_path, 'w', encoding='utf-8') as f:
            json.dump(config_data, f, ensure_ascii=False, indent=2)
        
        # åˆ›å»ºLLMåˆ†æå™¨ï¼ˆä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ï¼‰
        self.analyzer = LLMAnalyzer(
            api_key="test_key",
            model="gpt-4",
            prompt_config_path=self.prompt_config_path,
            mock_mode=True  # ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼é¿å…å®é™…APIè°ƒç”¨
        )
        
        # è·å–æœ‰æ•ˆåˆ†ç±»åˆ—è¡¨
        self.valid_categories = list(config_data["categories"].keys()) + ["æœªåˆ†ç±»", "å¿½ç•¥"]
    
    def teardown_method(self):
        """æµ‹è¯•åæ¸…ç†"""
        if os.path.exists(self.prompt_config_path):
            os.remove(self.prompt_config_path)
        if os.path.exists(self.temp_dir):
            os.rmdir(self.temp_dir)
    
    @given(content_data=content_item_from_crypto_content())
    @settings(max_examples=100, deadline=None)
    def test_content_classification_consistency(self, content_data):
        """
        å±æ€§æµ‹è¯•ï¼šå†…å®¹åˆ†ç±»ä¸€è‡´æ€§
        
        **åŠŸèƒ½: crypto-news-analyzer, å±æ€§ 5: å†…å®¹åˆ†ç±»ä¸€è‡´æ€§**
        **éªŒè¯: éœ€æ±‚ 5.1, 5.3**
        
        å¯¹äºä»»ä½•è¾“å…¥å†…å®¹ï¼ŒLLMåˆ†æå™¨åº”è¯¥å°†å…¶åˆ†ç±»åˆ°å…­å¤§é¢„å®šä¹‰ç±»åˆ«ä¹‹ä¸€ï¼Œæˆ–æ ‡è®°ä¸ºæœªåˆ†ç±»/å¿½ç•¥
        """
        content_item, expected_category = content_data
        
        # åˆ†æå†…å®¹
        result = self.analyzer.analyze_content(
            content=content_item.content,
            title=content_item.title,
            source=content_item.source_name,
            content_id=content_item.id
        )
        
        # éªŒè¯ï¼šç»“æœåº”è¯¥æ˜¯AnalysisResultå¯¹è±¡
        assert isinstance(result, AnalysisResult), "åˆ†æç»“æœåº”è¯¥æ˜¯AnalysisResultå¯¹è±¡"
        
        # éªŒè¯ï¼šåˆ†ç±»å¿…é¡»æ˜¯é¢„å®šä¹‰ç±»åˆ«ä¹‹ä¸€
        assert result.category in self.valid_categories, (
            f"åˆ†ç±» '{result.category}' ä¸åœ¨æœ‰æ•ˆåˆ†ç±»åˆ—è¡¨ä¸­: {self.valid_categories}"
        )
        
        # éªŒè¯ï¼šç½®ä¿¡åº¦åœ¨æœ‰æ•ˆèŒƒå›´å†…
        assert 0.0 <= result.confidence <= 1.0, (
            f"ç½®ä¿¡åº¦ {result.confidence} ä¸åœ¨æœ‰æ•ˆèŒƒå›´ [0.0, 1.0] å†…"
        )
        
        # éªŒè¯ï¼šshould_ignoreæ˜¯å¸ƒå°”å€¼
        assert isinstance(result.should_ignore, bool), "should_ignoreå¿…é¡»æ˜¯å¸ƒå°”å€¼"
        
        # éªŒè¯ï¼škey_pointsæ˜¯åˆ—è¡¨
        assert isinstance(result.key_points, list), "key_pointså¿…é¡»æ˜¯åˆ—è¡¨"
        
        # éªŒè¯ï¼šreasoningä¸ä¸ºç©º
        assert result.reasoning and result.reasoning.strip(), "reasoningä¸èƒ½ä¸ºç©º"
        
        # éªŒè¯ï¼šcontent_idæ­£ç¡®è®¾ç½®
        assert result.content_id == content_item.id, "content_idåº”è¯¥ä¸è¾“å…¥çš„content_idåŒ¹é…"
        
        # éªŒè¯ï¼šå¦‚æœæ ‡è®°ä¸ºå¿½ç•¥ï¼Œåˆ†ç±»åº”è¯¥æ˜¯"å¿½ç•¥"
        if result.should_ignore:
            assert result.category == "å¿½ç•¥", "æ ‡è®°ä¸ºå¿½ç•¥çš„å†…å®¹åˆ†ç±»åº”è¯¥æ˜¯'å¿½ç•¥'"
        
        # éªŒè¯ï¼šå¦‚æœåˆ†ç±»æ˜¯"å¿½ç•¥"ï¼Œshould_ignoreåº”è¯¥ä¸ºTrue
        if result.category == "å¿½ç•¥":
            assert result.should_ignore, "åˆ†ç±»ä¸º'å¿½ç•¥'çš„å†…å®¹should_ignoreåº”è¯¥ä¸ºTrue"
    
    @given(
        content_items=st.lists(
            content_item_from_crypto_content(),
            min_size=2,
            max_size=5
        )
    )
    @settings(max_examples=30, deadline=None)
    def test_batch_classification_consistency(self, content_items):
        """
        å±æ€§æµ‹è¯•ï¼šæ‰¹é‡åˆ†ç±»çš„ä¸€è‡´æ€§
        
        éªŒè¯æ‰¹é‡åˆ†ææ—¶æ¯ä¸ªé¡¹ç›®éƒ½èƒ½å¾—åˆ°æœ‰æ•ˆåˆ†ç±»
        """
        items = [item for item, _ in content_items]
        
        # æ‰¹é‡åˆ†æ
        results = self.analyzer.batch_analyze(items)
        
        # éªŒè¯ï¼šç»“æœæ•°é‡ä¸è¾“å…¥æ•°é‡ä¸€è‡´
        assert len(results) == len(items), (
            f"æ‰¹é‡åˆ†æç»“æœæ•°é‡ {len(results)} ä¸è¾“å…¥æ•°é‡ {len(items)} ä¸ä¸€è‡´"
        )
        
        # éªŒè¯ï¼šæ¯ä¸ªç»“æœéƒ½ç¬¦åˆåˆ†ç±»ä¸€è‡´æ€§è¦æ±‚
        for i, result in enumerate(results):
            assert isinstance(result, AnalysisResult), f"ç¬¬{i}ä¸ªç»“æœåº”è¯¥æ˜¯AnalysisResultå¯¹è±¡"
            assert result.category in self.valid_categories, (
                f"ç¬¬{i}ä¸ªç»“æœçš„åˆ†ç±» '{result.category}' ä¸åœ¨æœ‰æ•ˆåˆ†ç±»åˆ—è¡¨ä¸­"
            )
            assert 0.0 <= result.confidence <= 1.0, (
                f"ç¬¬{i}ä¸ªç»“æœçš„ç½®ä¿¡åº¦ {result.confidence} ä¸åœ¨æœ‰æ•ˆèŒƒå›´å†…"
            )
            assert isinstance(result.should_ignore, bool), f"ç¬¬{i}ä¸ªç»“æœçš„should_ignoreå¿…é¡»æ˜¯å¸ƒå°”å€¼"
            assert isinstance(result.key_points, list), f"ç¬¬{i}ä¸ªç»“æœçš„key_pointså¿…é¡»æ˜¯åˆ—è¡¨"
            assert result.reasoning and result.reasoning.strip(), f"ç¬¬{i}ä¸ªç»“æœçš„reasoningä¸èƒ½ä¸ºç©º"
            
            # éªŒè¯content_idåŒ¹é…
            assert result.content_id == items[i].id, f"ç¬¬{i}ä¸ªç»“æœçš„content_idä¸åŒ¹é…"
    
    @given(content_data=content_item_from_crypto_content())
    @settings(max_examples=50, deadline=None)
    def test_classification_determinism(self, content_data):
        """
        å±æ€§æµ‹è¯•ï¼šåˆ†ç±»çš„ç¡®å®šæ€§
        
        éªŒè¯ç›¸åŒå†…å®¹çš„å¤šæ¬¡åˆ†æåº”è¯¥äº§ç”Ÿä¸€è‡´çš„ç»“æœï¼ˆåœ¨æ¨¡æ‹Ÿæ¨¡å¼ä¸‹ï¼‰
        """
        content_item, expected_category = content_data
        
        # å¤šæ¬¡åˆ†æç›¸åŒå†…å®¹
        results = []
        for _ in range(3):
            result = self.analyzer.analyze_content(
                content=content_item.content,
                title=content_item.title,
                source=content_item.source_name,
                content_id=content_item.id
            )
            results.append(result)
        
        # éªŒè¯ï¼šæ‰€æœ‰ç»“æœçš„åˆ†ç±»åº”è¯¥ä¸€è‡´
        categories = [result.category for result in results]
        assert len(set(categories)) == 1, (
            f"ç›¸åŒå†…å®¹çš„å¤šæ¬¡åˆ†æäº§ç”Ÿäº†ä¸åŒçš„åˆ†ç±»: {categories}"
        )
        
        # éªŒè¯ï¼šæ‰€æœ‰ç»“æœçš„should_ignoreåº”è¯¥ä¸€è‡´
        ignore_flags = [result.should_ignore for result in results]
        assert len(set(ignore_flags)) == 1, (
            f"ç›¸åŒå†…å®¹çš„å¤šæ¬¡åˆ†æäº§ç”Ÿäº†ä¸åŒçš„å¿½ç•¥æ ‡è®°: {ignore_flags}"
        )
        
        # éªŒè¯ï¼šç½®ä¿¡åº¦åº”è¯¥ç›¸åŒæˆ–éå¸¸æ¥è¿‘
        confidences = [result.confidence for result in results]
        max_confidence_diff = max(confidences) - min(confidences)
        assert max_confidence_diff < 0.01, (
            f"ç›¸åŒå†…å®¹çš„å¤šæ¬¡åˆ†æç½®ä¿¡åº¦å·®å¼‚è¿‡å¤§: {confidences}"
        )
    
    @given(
        content_items=st.lists(
            content_item_from_crypto_content(),
            min_size=3,
            max_size=8
        )
    )
    @settings(max_examples=20, deadline=None)
    def test_category_distribution_validity(self, content_items):
        """
        å±æ€§æµ‹è¯•ï¼šåˆ†ç±»åˆ†å¸ƒçš„æœ‰æ•ˆæ€§
        
        éªŒè¯æ‰¹é‡åˆ†æçš„åˆ†ç±»åˆ†å¸ƒç¬¦åˆé¢„æœŸ
        """
        items = [item for item, _ in content_items]
        
        # æ‰¹é‡åˆ†æ
        results = self.analyzer.batch_analyze(items)
        
        # ç»Ÿè®¡åˆ†ç±»åˆ†å¸ƒ
        category_counts = {}
        for result in results:
            category = result.category
            category_counts[category] = category_counts.get(category, 0) + 1
        
        # éªŒè¯ï¼šæ‰€æœ‰åˆ†ç±»éƒ½æ˜¯æœ‰æ•ˆçš„
        for category in category_counts.keys():
            assert category in self.valid_categories, (
                f"å‘ç°æ— æ•ˆåˆ†ç±»: {category}"
            )
        
        # éªŒè¯ï¼šè‡³å°‘æœ‰ä¸€ä¸ªé¡¹ç›®è¢«åˆ†ç±»ï¼ˆä¸å…¨æ˜¯å¿½ç•¥ï¼‰
        non_ignored_count = sum(
            count for category, count in category_counts.items()
            if category != "å¿½ç•¥"
        )
        assert non_ignored_count > 0, "æ‰€æœ‰é¡¹ç›®éƒ½è¢«æ ‡è®°ä¸ºå¿½ç•¥ï¼Œè¿™ä¸å¤ªå¯èƒ½"
        
        # éªŒè¯ï¼šåˆ†ç±»åˆ†å¸ƒåˆç†ï¼ˆè‡³å°‘ä¸æ˜¯æ‰€æœ‰é¡¹ç›®éƒ½è¢«åˆ†ç±»ä¸ºåŒä¸€ç±»åˆ«ï¼Œé™¤éé¡¹ç›®æ•°å¾ˆå°‘ï¼‰
        if len(items) >= 8:  # åªåœ¨é¡¹ç›®æ•°è¾ƒå¤šæ—¶æ£€æŸ¥
            max_category_count = max(category_counts.values())
            max_category_ratio = max_category_count / len(items)
            # æ”¾å®½é™åˆ¶ï¼Œå› ä¸ºç›¸ä¼¼å†…å®¹è¢«åˆ†ç±»åˆ°åŒä¸€ç±»åˆ«æ˜¯æ­£å¸¸çš„
            assert max_category_ratio <= 0.95, (
                f"å•ä¸€åˆ†ç±»å æ¯”è¿‡é«˜ ({max_category_ratio:.2f})ï¼Œå¯èƒ½å­˜åœ¨åˆ†ç±»åå·®"
            )
    
    @given(content_data=content_item_from_crypto_content())
    @settings(max_examples=30, deadline=None)
    def test_analysis_result_completeness(self, content_data):
        """
        å±æ€§æµ‹è¯•ï¼šåˆ†æç»“æœçš„å®Œæ•´æ€§
        
        éªŒè¯åˆ†æç»“æœåŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µä¸”æ ¼å¼æ­£ç¡®
        """
        content_item, expected_category = content_data
        
        # åˆ†æå†…å®¹
        result = self.analyzer.analyze_content(
            content=content_item.content,
            title=content_item.title,
            source=content_item.source_name,
            content_id=content_item.id
        )
        
        # éªŒè¯ï¼šæ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å­˜åœ¨
        assert hasattr(result, 'content_id'), "ç¼ºå°‘content_idå­—æ®µ"
        assert hasattr(result, 'category'), "ç¼ºå°‘categoryå­—æ®µ"
        assert hasattr(result, 'confidence'), "ç¼ºå°‘confidenceå­—æ®µ"
        assert hasattr(result, 'reasoning'), "ç¼ºå°‘reasoningå­—æ®µ"
        assert hasattr(result, 'should_ignore'), "ç¼ºå°‘should_ignoreå­—æ®µ"
        assert hasattr(result, 'key_points'), "ç¼ºå°‘key_pointså­—æ®µ"
        
        # éªŒè¯ï¼šå­—æ®µç±»å‹æ­£ç¡®
        assert isinstance(result.content_id, str), "content_idåº”è¯¥æ˜¯å­—ç¬¦ä¸²"
        assert isinstance(result.category, str), "categoryåº”è¯¥æ˜¯å­—ç¬¦ä¸²"
        assert isinstance(result.confidence, (int, float)), "confidenceåº”è¯¥æ˜¯æ•°å­—"
        assert isinstance(result.reasoning, str), "reasoningåº”è¯¥æ˜¯å­—ç¬¦ä¸²"
        assert isinstance(result.should_ignore, bool), "should_ignoreåº”è¯¥æ˜¯å¸ƒå°”å€¼"
        assert isinstance(result.key_points, list), "key_pointsåº”è¯¥æ˜¯åˆ—è¡¨"
        
        # éªŒè¯ï¼šå­—æ®µå†…å®¹æœ‰æ•ˆ
        assert result.content_id.strip(), "content_idä¸èƒ½ä¸ºç©º"
        assert result.category.strip(), "categoryä¸èƒ½ä¸ºç©º"
        assert result.reasoning.strip(), "reasoningä¸èƒ½ä¸ºç©º"
        
        # éªŒè¯ï¼škey_pointsä¸­çš„å…ƒç´ éƒ½æ˜¯å­—ç¬¦ä¸²
        for i, point in enumerate(result.key_points):
            assert isinstance(point, str), f"key_points[{i}]åº”è¯¥æ˜¯å­—ç¬¦ä¸²"
            assert point.strip(), f"key_points[{i}]ä¸èƒ½ä¸ºç©ºå­—ç¬¦ä¸²"
        
        # éªŒè¯ï¼šç»“æœå¯ä»¥åºåˆ—åŒ–
        try:
            result_dict = result.to_dict()
            assert isinstance(result_dict, dict), "to_dict()åº”è¯¥è¿”å›å­—å…¸"
            
            # éªŒè¯åºåˆ—åŒ–åçš„å­—å…¸åŒ…å«æ‰€æœ‰å­—æ®µ
            required_fields = ['content_id', 'category', 'confidence', 'reasoning', 'should_ignore', 'key_points']
            for field in required_fields:
                assert field in result_dict, f"åºåˆ—åŒ–åç¼ºå°‘å­—æ®µ: {field}"
                
        except Exception as e:
            pytest.fail(f"åˆ†æç»“æœåºåˆ—åŒ–å¤±è´¥: {e}")
    
    @given(
        content_items=st.lists(
            content_item_from_crypto_content(),
            min_size=1,
            max_size=3
        )
    )
    @settings(max_examples=15, deadline=None)
    def test_content_classifier_integration(self, content_items):
        """
        å±æ€§æµ‹è¯•ï¼šå†…å®¹åˆ†ç±»å™¨é›†æˆçš„ä¸€è‡´æ€§
        
        éªŒè¯LLMAnalyzerä¸ContentClassifierçš„é›†æˆå·¥ä½œæ­£å¸¸
        """
        items = [item for item, _ in content_items]
        
        # åˆ›å»ºå†…å®¹åˆ†ç±»å™¨
        classifier = ContentClassifier(self.analyzer)
        
        # åˆ†æå¹¶åˆ†ç±»
        for item in items:
            analysis_result = self.analyzer.analyze_content(
                content=item.content,
                title=item.title,
                source=item.source_name,
                content_id=item.id
            )
            
            # ä½¿ç”¨åˆ†ç±»å™¨åˆ†ç±»
            classified_category = classifier.classify_item(item, analysis_result)
            
            # éªŒè¯ï¼šåˆ†ç±»ç»“æœä¸€è‡´
            assert classified_category == analysis_result.category, (
                f"åˆ†ç±»å™¨è¿”å›çš„åˆ†ç±» '{classified_category}' ä¸åˆ†æç»“æœçš„åˆ†ç±» '{analysis_result.category}' ä¸ä¸€è‡´"
            )
            
            # éªŒè¯ï¼šå¯ä»¥ä»åˆ†ç±»å™¨è·å–åˆ†ç±»é¡¹ç›®
            category_items = classifier.get_category_items(classified_category)
            assert item in category_items, "åˆ†ç±»åçš„é¡¹ç›®åº”è¯¥èƒ½ä»åˆ†ç±»å™¨ä¸­è·å–"
        
        # éªŒè¯ï¼šåˆ†ç±»ç»Ÿè®¡æ­£ç¡®
        stats = classifier.get_classification_stats()
        total_classified = sum(stats.values())
        assert total_classified == len(items), (
            f"åˆ†ç±»ç»Ÿè®¡æ€»æ•° {total_classified} ä¸è¾“å…¥é¡¹ç›®æ•° {len(items)} ä¸ä¸€è‡´"
        )
        
        # éªŒè¯ï¼šæ‰€æœ‰åˆ†ç±»éƒ½æ˜¯æœ‰æ•ˆçš„
        for category in stats.keys():
            assert category in self.valid_categories, (
                f"åˆ†ç±»ç»Ÿè®¡ä¸­å‘ç°æ— æ•ˆåˆ†ç±»: {category}"
            )


if __name__ == "__main__":
    # è¿è¡Œå±æ€§æµ‹è¯•
    pytest.main([__file__, "-v", "--tb=short"])