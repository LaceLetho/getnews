#!/usr/bin/env python3
"""
LLMåˆ†æå™¨å•å…ƒæµ‹è¯•

æµ‹è¯•æç¤ºè¯æ„å»ºã€å“åº”è§£æå’Œå„ç§åˆ†ç±»åœºæ™¯çš„è¾¹ç•Œæƒ…å†µ
"""

import os
import sys
import unittest
import json
import tempfile
from unittest.mock import Mock, patch, MagicMock
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from crypto_news_analyzer.analyzers.llm_analyzer import LLMAnalyzer, LLMResponse, ContentClassifier
from crypto_news_analyzer.analyzers.prompt_manager import PromptManager, DynamicCategoryManager, CategoryConfig
from crypto_news_analyzer.models import ContentItem, AnalysisResult


class TestPromptConstruction(unittest.TestCase):
    """æµ‹è¯•æç¤ºè¯æ„å»ºåŠŸèƒ½"""
    
    def setUp(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        # åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶
        self.temp_config = {
            "prompt_template": "åˆ†æä»¥ä¸‹å†…å®¹ï¼š\n\n{categories_description}\n\nå¿½ç•¥æ ‡å‡†ï¼š\n{ignore_criteria}\n\nå†…å®¹ï¼š{content}\næ ‡é¢˜ï¼š{title}\næ¥æºï¼š{source}\n\n{output_format}",
            "categories": {
                "å¤§æˆ·åŠ¨å‘": {
                    "description": "å¤§æˆ·èµ„é‡‘æµåŠ¨å’Œæ€åº¦å˜åŒ–",
                    "criteria": ["å·¨é²¸èµ„é‡‘æµå…¥æµå‡º", "å¤§æˆ·æ€åº¦å˜åŒ–"],
                    "examples": ["æŸå·¨é²¸åœ°å€è½¬ç§»10000 ETH"],
                    "priority": 1
                },
                "åˆ©ç‡äº‹ä»¶": {
                    "description": "ç¾è”å‚¨ç›¸å…³çš„åˆ©ç‡æ”¿ç­–äº‹ä»¶",
                    "criteria": ["ç¾è”å‚¨å§”å‘˜å‘è¨€", "FOMCä¼šè®®"],
                    "examples": ["é²å¨å°”å‘è¡¨é¹°æ´¾è¨€è®º"],
                    "priority": 1
                }
            },
            "ignore_criteria": [
                "å¹¿å‘Šå’Œè½¯æ–‡",
                "é‡å¤ä¿¡æ¯",
                "æƒ…ç»ªå‘æ³„"
            ],
            "output_format": "è¯·ä»¥JSONæ ¼å¼è¾“å‡ºç»“æœ",
            "llm_settings": {
                "temperature": 0.1,
                "max_tokens": 1000,
                "model": "gpt-4"
            }
        }
        
        # åˆ›å»ºä¸´æ—¶é…ç½®æ–‡ä»¶
        self.temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='.json', delete=False)
        json.dump(self.temp_config, self.temp_file, ensure_ascii=False, indent=2)
        self.temp_file.close()
        
        self.prompt_manager = PromptManager(self.temp_file.name)
    
    def tearDown(self):
        """æ¸…ç†ä¸´æ—¶æ–‡ä»¶"""
        os.unlink(self.temp_file.name)
    
    def test_load_prompt_template(self):
        """æµ‹è¯•åŠ è½½æç¤ºè¯æ¨¡æ¿"""
        template = self.prompt_manager.load_prompt_template()
        
        self.assertIn("{categories_description}", template)
        self.assertIn("{ignore_criteria}", template)
        self.assertIn("{content}", template)
        self.assertIn("{title}", template)
        self.assertIn("{source}", template)
        self.assertIn("{output_format}", template)
    
    def test_load_categories_config(self):
        """æµ‹è¯•åŠ è½½åˆ†ç±»é…ç½®"""
        categories = self.prompt_manager.load_categories_config()
        
        self.assertIn("å¤§æˆ·åŠ¨å‘", categories)
        self.assertIn("åˆ©ç‡äº‹ä»¶", categories)
        
        whale_category = categories["å¤§æˆ·åŠ¨å‘"]
        self.assertEqual(whale_category.name, "å¤§æˆ·åŠ¨å‘")
        self.assertEqual(whale_category.description, "å¤§æˆ·èµ„é‡‘æµåŠ¨å’Œæ€åº¦å˜åŒ–")
        self.assertIn("å·¨é²¸èµ„é‡‘æµå…¥æµå‡º", whale_category.criteria)
        self.assertIn("æŸå·¨é²¸åœ°å€è½¬ç§»10000 ETH", whale_category.examples)
        self.assertEqual(whale_category.priority, 1)
    
    def test_build_analysis_prompt(self):
        """æµ‹è¯•æ„å»ºåˆ†ææç¤ºè¯"""
        content = "æŸå·¨é²¸åœ°å€è½¬ç§»15000ä¸ªETHåˆ°äº¤æ˜“æ‰€"
        title = "å·¨é²¸èµ„é‡‘è½¬ç§»"
        source = "æµ‹è¯•æ¥æº"
        
        prompt = self.prompt_manager.build_analysis_prompt(content, title, source)
        
        # éªŒè¯æç¤ºè¯åŒ…å«æ‰€æœ‰å¿…è¦ä¿¡æ¯
        self.assertIn(content, prompt)
        self.assertIn(title, prompt)
        self.assertIn(source, prompt)
        self.assertIn("å¤§æˆ·åŠ¨å‘", prompt)
        self.assertIn("åˆ©ç‡äº‹ä»¶", prompt)
        self.assertIn("å¹¿å‘Šå’Œè½¯æ–‡", prompt)
        self.assertIn("è¯·ä»¥JSONæ ¼å¼è¾“å‡ºç»“æœ", prompt)
    
    def test_validate_prompt_template(self):
        """æµ‹è¯•æç¤ºè¯æ¨¡æ¿éªŒè¯"""
        # æµ‹è¯•æœ‰æ•ˆæ¨¡æ¿
        valid_template = "åˆ†æï¼š{categories_description}{ignore_criteria}{content}{title}{source}{output_format}"
        self.assertTrue(self.prompt_manager.validate_prompt_template(valid_template))
        
        # æµ‹è¯•æ— æ•ˆæ¨¡æ¿ï¼ˆç¼ºå°‘å ä½ç¬¦ï¼‰
        invalid_template = "åˆ†æï¼š{content}{title}"
        self.assertFalse(self.prompt_manager.validate_prompt_template(invalid_template))
    
    def test_get_llm_settings(self):
        """æµ‹è¯•è·å–LLMè®¾ç½®"""
        settings = self.prompt_manager.get_llm_settings()
        
        self.assertEqual(settings["temperature"], 0.1)
        self.assertEqual(settings["max_tokens"], 1000)
        # ç°åœ¨ä»ä¸»é…ç½®æ–‡ä»¶è¯»å–ï¼Œåº”è¯¥æ˜¯ MiniMax-M2.1
        self.assertEqual(settings["model"], "MiniMax-M2.1")


class TestResponseParsing(unittest.TestCase):
    """æµ‹è¯•å“åº”è§£æåŠŸèƒ½"""
    
    def setUp(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        self.analyzer = LLMAnalyzer(
            api_key="test_key",
            model="test_model",
            mock_mode=True
        )
    
    def test_parse_valid_json_response(self):
        """æµ‹è¯•è§£ææœ‰æ•ˆçš„JSONå“åº”"""
        json_response = json.dumps({
            "category": "å¤§æˆ·åŠ¨å‘",
            "confidence": 0.95,
            "reasoning": "è¿™æ˜¯å…¸å‹çš„å·¨é²¸èµ„é‡‘æµåŠ¨äº‹ä»¶",
            "should_ignore": False,
            "key_points": ["å·¨é²¸è½¬ç§»", "å¤§é¢äº¤æ˜“"]
        }, ensure_ascii=False)
        
        parsed = self.analyzer.parse_llm_response(json_response)
        
        self.assertEqual(parsed.category, "å¤§æˆ·åŠ¨å‘")
        self.assertEqual(parsed.confidence, 0.95)
        self.assertEqual(parsed.reasoning, "è¿™æ˜¯å…¸å‹çš„å·¨é²¸èµ„é‡‘æµåŠ¨äº‹ä»¶")
        self.assertFalse(parsed.should_ignore)
        self.assertEqual(len(parsed.key_points), 2)
        self.assertIn("å·¨é²¸è½¬ç§»", parsed.key_points)
    
    def test_parse_response_with_think_tags(self):
        """æµ‹è¯•è§£æåŒ…å«<think>æ ‡ç­¾çš„å“åº”"""
        response_with_think = """<think>
        è¿™ä¸ªå†…å®¹æ¶‰åŠå¤§é¢èµ„é‡‘è½¬ç§»ï¼Œåº”è¯¥å½’ç±»ä¸ºå¤§æˆ·åŠ¨å‘ã€‚
        ç½®ä¿¡åº¦è¾ƒé«˜ï¼Œå› ä¸ºæœ‰å…·ä½“çš„æ•°é¢å’Œåœ°å€ä¿¡æ¯ã€‚
        </think>
        
        {
            "category": "å¤§æˆ·åŠ¨å‘",
            "confidence": 0.92,
            "reasoning": "æ¶‰åŠå¤§é¢ETHè½¬ç§»ï¼Œç¬¦åˆå·¨é²¸æ´»åŠ¨ç‰¹å¾",
            "should_ignore": false,
            "key_points": ["15000 ETH", "äº¤æ˜“æ‰€è½¬ç§»"]
        }"""
        
        parsed = self.analyzer.parse_llm_response(response_with_think)
        
        self.assertEqual(parsed.category, "å¤§æˆ·åŠ¨å‘")
        self.assertEqual(parsed.confidence, 0.92)
        self.assertFalse(parsed.should_ignore)
        self.assertEqual(len(parsed.key_points), 2)
    
    def test_parse_malformed_json_response(self):
        """æµ‹è¯•è§£ææ ¼å¼é”™è¯¯çš„JSONå“åº”"""
        malformed_json = '{"category": "invalid_category", "confidence": 0.95, "reasoning": "æµ‹è¯•"'  # ç¼ºå°‘ç»“æŸæ‹¬å·
        
        parsed = self.analyzer.parse_llm_response(malformed_json)
        
        # åº”è¯¥è¿”å›é»˜è®¤å€¼è€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
        self.assertEqual(parsed.category, "æœªåˆ†ç±»")
        self.assertEqual(parsed.confidence, 0.5)  # æ–‡æœ¬è§£æçš„é»˜è®¤ç½®ä¿¡åº¦
        self.assertIsInstance(parsed.reasoning, str)
    
    def test_parse_text_response_fallback(self):
        """æµ‹è¯•æ–‡æœ¬å“åº”çš„å¤‡ç”¨è§£æ"""
        text_response = "è¿™ä¸ªå†…å®¹å±äºå¤§æˆ·åŠ¨å‘ç±»åˆ«ï¼Œå› ä¸ºæ¶‰åŠå·¨é²¸èµ„é‡‘è½¬ç§»ã€‚åº”è¯¥å¿½ç•¥è¿™ç±»å¹¿å‘Šå†…å®¹ã€‚"
        
        parsed = self.analyzer.parse_llm_response(text_response)
        
        # åº”è¯¥èƒ½ä»æ–‡æœ¬ä¸­æå–åŸºæœ¬ä¿¡æ¯
        self.assertIsInstance(parsed.category, str)
        self.assertIsInstance(parsed.confidence, float)
        self.assertIsInstance(parsed.reasoning, str)
        self.assertIsInstance(parsed.should_ignore, bool)
    
    def test_clean_response_text(self):
        """æµ‹è¯•å“åº”æ–‡æœ¬æ¸…ç†åŠŸèƒ½"""
        # æµ‹è¯•ç§»é™¤<think>æ ‡ç­¾
        response_with_tags = """<think>æ€è€ƒè¿‡ç¨‹</think>{"category": "æµ‹è¯•"}"""
        cleaned = self.analyzer._clean_response_text(response_with_tags)
        self.assertEqual(cleaned, '{"category": "æµ‹è¯•"}')
        
        # æµ‹è¯•æå–JSONå¯¹è±¡
        response_with_extra = """è¿™æ˜¯ä¸€äº›é¢å¤–æ–‡æœ¬ {"category": "æµ‹è¯•", "confidence": 0.8} è¿˜æœ‰æ›´å¤šæ–‡æœ¬"""
        cleaned = self.analyzer._clean_response_text(response_with_extra)
        self.assertEqual(cleaned, '{"category": "æµ‹è¯•", "confidence": 0.8}')


class TestClassificationScenarios(unittest.TestCase):
    """æµ‹è¯•å„ç§åˆ†ç±»åœºæ™¯"""
    
    def setUp(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        self.analyzer = LLMAnalyzer(
            api_key="test_key",
            model="test_model",
            mock_mode=True
        )
    
    def test_whale_movement_classification(self):
        """æµ‹è¯•å¤§æˆ·åŠ¨å‘åˆ†ç±»"""
        content = "å·¨é²¸åœ°å€è½¬ç§»15000ä¸ªETHåˆ°Binanceäº¤æ˜“æ‰€ï¼Œä»·å€¼çº¦5000ä¸‡ç¾å…ƒ"
        
        result = self.analyzer.analyze_content(content, "å·¨é²¸èµ„é‡‘è½¬ç§»", "æµ‹è¯•æ¥æº")
        
        self.assertEqual(result.category, "å¤§æˆ·åŠ¨å‘")
        self.assertGreater(result.confidence, 0.8)
        self.assertFalse(result.should_ignore)
        self.assertIsInstance(result.key_points, list)
    
    def test_interest_rate_classification(self):
        """æµ‹è¯•åˆ©ç‡äº‹ä»¶åˆ†ç±»"""
        content = "ç¾è”å‚¨ä¼šè®®çºªè¦æ˜¾ç¤ºï¼Œå¤šæ•°å§”å‘˜æ”¯æŒåœ¨ä¸‹æ¬¡ä¼šè®®ä¸­è€ƒè™‘é™æ¯25ä¸ªåŸºç‚¹"
        
        result = self.analyzer.analyze_content(content, "ç¾è”å‚¨é™æ¯é¢„æœŸ", "æµ‹è¯•æ¥æº")
        
        self.assertEqual(result.category, "åˆ©ç‡äº‹ä»¶")
        self.assertGreater(result.confidence, 0.8)
        self.assertFalse(result.should_ignore)
    
    def test_security_event_classification(self):
        """æµ‹è¯•å®‰å…¨äº‹ä»¶åˆ†ç±»"""
        content = "DeFiåè®®é­å—é‡å…¥æ¼æ´æ”»å‡»ï¼Œé»‘å®¢ç›—å–500ä¸‡ç¾å…ƒåŠ å¯†è´§å¸"
        
        result = self.analyzer.analyze_content(content, "DeFiåè®®è¢«é»‘", "æµ‹è¯•æ¥æº")
        
        self.assertEqual(result.category, "å®‰å…¨äº‹ä»¶")
        self.assertGreater(result.confidence, 0.8)
        self.assertFalse(result.should_ignore)
    
    def test_advertisement_filtering(self):
        """æµ‹è¯•å¹¿å‘Šå†…å®¹è¿‡æ»¤"""
        content = "ğŸš€è¶…é«˜æ”¶ç›Šç‡DeFiæŒ–çŸ¿é¡¹ç›®ï¼ç«‹å³å‚ä¸ï¼åƒè½½éš¾é€¢çš„æœºä¼šï¼"
        
        result = self.analyzer.analyze_content(content, "ğŸš€è¶…é«˜æ”¶ç›Šç‡é¡¹ç›®", "æµ‹è¯•æ¥æº")
        
        self.assertTrue(result.should_ignore)
        self.assertGreater(result.confidence, 0.8)
    
    def test_uncategorized_content(self):
        """æµ‹è¯•æœªåˆ†ç±»å†…å®¹"""
        content = "ä»Šå¤©å¤©æ°”ä¸é”™ï¼Œé€‚åˆå‡ºé—¨æ•£æ­¥"
        
        result = self.analyzer.analyze_content(content, "å¤©æ°”ä¿¡æ¯", "æµ‹è¯•æ¥æº")
        
        self.assertEqual(result.category, "æœªåˆ†ç±»")
        self.assertIsInstance(result.confidence, float)
        self.assertFalse(result.should_ignore)


class TestEdgeCases(unittest.TestCase):
    """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
    
    def setUp(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        self.analyzer = LLMAnalyzer(
            api_key="test_key",
            model="test_model",
            mock_mode=True
        )
    
    def test_empty_content(self):
        """æµ‹è¯•ç©ºå†…å®¹"""
        result = self.analyzer.analyze_content("", "", "")
        
        self.assertIsInstance(result, AnalysisResult)
        self.assertIsInstance(result.category, str)
        self.assertIsInstance(result.confidence, float)
    
    def test_very_long_content(self):
        """æµ‹è¯•è¶…é•¿å†…å®¹"""
        long_content = "è¿™æ˜¯ä¸€ä¸ªå¾ˆé•¿çš„å†…å®¹ã€‚" * 1000  # åˆ›å»ºå¾ˆé•¿çš„æ–‡æœ¬
        
        result = self.analyzer.analyze_content(long_content, "è¶…é•¿å†…å®¹æµ‹è¯•", "æµ‹è¯•æ¥æº")
        
        self.assertIsInstance(result, AnalysisResult)
        self.assertIsInstance(result.category, str)
    
    def test_special_characters_content(self):
        """æµ‹è¯•åŒ…å«ç‰¹æ®Šå­—ç¬¦çš„å†…å®¹"""
        special_content = "æµ‹è¯•å†…å®¹åŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼š@#$%^&*()[]{}|\\:;\"'<>?,./"
        
        result = self.analyzer.analyze_content(special_content, "ç‰¹æ®Šå­—ç¬¦æµ‹è¯•", "æµ‹è¯•æ¥æº")
        
        self.assertIsInstance(result, AnalysisResult)
        self.assertIsInstance(result.category, str)
    
    def test_unicode_content(self):
        """æµ‹è¯•Unicodeå†…å®¹"""
        unicode_content = "æµ‹è¯•Unicodeå­—ç¬¦ï¼šğŸš€ğŸ’°ğŸ“ˆğŸ”¥âš¡ï¸ğŸŒŸğŸ’ğŸ¯"
        
        result = self.analyzer.analyze_content(unicode_content, "Unicodeæµ‹è¯•", "æµ‹è¯•æ¥æº")
        
        self.assertIsInstance(result, AnalysisResult)
        self.assertIsInstance(result.category, str)
    
    def test_mixed_language_content(self):
        """æµ‹è¯•æ··åˆè¯­è¨€å†…å®¹"""
        mixed_content = "Bitcoin price surged to $50,000 æ¯”ç‰¹å¸ä»·æ ¼é£™å‡è‡³5ä¸‡ç¾å…ƒ"
        
        result = self.analyzer.analyze_content(mixed_content, "æ··åˆè¯­è¨€æµ‹è¯•", "æµ‹è¯•æ¥æº")
        
        self.assertIsInstance(result, AnalysisResult)
        self.assertIsInstance(result.category, str)
    
    def test_invalid_category_response(self):
        """æµ‹è¯•æ— æ•ˆåˆ†ç±»å“åº”çš„å¤„ç†"""
        # æ¨¡æ‹Ÿè¿”å›æ— æ•ˆåˆ†ç±»çš„æƒ…å†µ
        with patch.object(self.analyzer, '_call_llm_api') as mock_api:
            mock_api.return_value = json.dumps({
                "category": "æ— æ•ˆåˆ†ç±»åç§°",
                "confidence": 0.9,
                "reasoning": "æµ‹è¯•",
                "should_ignore": False,
                "key_points": []
            }, ensure_ascii=False)
            
            result = self.analyzer.analyze_content("æµ‹è¯•å†…å®¹", "æµ‹è¯•æ ‡é¢˜", "æµ‹è¯•æ¥æº")
            
            # åº”è¯¥è¢«ä¿®æ­£ä¸º"æœªåˆ†ç±»"
            self.assertEqual(result.category, "æœªåˆ†ç±»")


class TestBatchAnalysis(unittest.TestCase):
    """æµ‹è¯•æ‰¹é‡åˆ†æåŠŸèƒ½"""
    
    def setUp(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        self.analyzer = LLMAnalyzer(
            api_key="test_key",
            model="test_model",
            mock_mode=True
        )
    
    def test_batch_analyze_multiple_items(self):
        """æµ‹è¯•æ‰¹é‡åˆ†æå¤šä¸ªå†…å®¹é¡¹"""
        items = [
            ContentItem(
                id="test_1",
                title="å·¨é²¸è½¬ç§»ETH",
                content="æŸå·¨é²¸åœ°å€è½¬ç§»10000ä¸ªETH",
                source_name="æµ‹è¯•æ¥æº1",
                url="https://example.com/1",
                publish_time=datetime.now(),
                source_type="rss"
            ),
            ContentItem(
                id="test_2",
                title="ç¾è”å‚¨æ”¿ç­–",
                content="ç¾è”å‚¨æš—ç¤ºå¯èƒ½è°ƒæ•´åˆ©ç‡æ”¿ç­–",
                source_name="æµ‹è¯•æ¥æº2",
                url="https://example.com/2",
                publish_time=datetime.now(),
                source_type="rss"
            )
        ]
        
        results = self.analyzer.batch_analyze(items)
        
        self.assertEqual(len(results), 2)
        for i, result in enumerate(results):
            self.assertEqual(result.content_id, items[i].id)
            self.assertIsInstance(result.category, str)
            self.assertIsInstance(result.confidence, float)
    
    def test_batch_analyze_empty_list(self):
        """æµ‹è¯•æ‰¹é‡åˆ†æç©ºåˆ—è¡¨"""
        results = self.analyzer.batch_analyze([])
        
        self.assertEqual(len(results), 0)
        self.assertIsInstance(results, list)


class TestContentClassifier(unittest.TestCase):
    """æµ‹è¯•å†…å®¹åˆ†ç±»å™¨"""
    
    def setUp(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        self.analyzer = LLMAnalyzer(
            api_key="test_key",
            model="test_model",
            mock_mode=True
        )
        self.classifier = ContentClassifier(self.analyzer)
    
    def test_classify_item(self):
        """æµ‹è¯•åˆ†ç±»å•ä¸ªå†…å®¹é¡¹"""
        item = ContentItem(
            id="test_1",
            title="æµ‹è¯•æ ‡é¢˜",
            content="æµ‹è¯•å†…å®¹",
            source_name="æµ‹è¯•æ¥æº",
            url="https://example.com/test",
            publish_time=datetime.now(),
            source_type="rss"
        )
        
        analysis = AnalysisResult(
            content_id="test_1",
            category="å¤§æˆ·åŠ¨å‘",
            confidence=0.9,
            reasoning="æµ‹è¯•æ¨ç†",
            should_ignore=False,
            key_points=["æµ‹è¯•ç‚¹"]
        )
        
        category = self.classifier.classify_item(item, analysis)
        
        self.assertEqual(category, "å¤§æˆ·åŠ¨å‘")
        
        # éªŒè¯å†…å®¹é¡¹è¢«æ­£ç¡®å­˜å‚¨
        category_items = self.classifier.get_category_items("å¤§æˆ·åŠ¨å‘")
        self.assertEqual(len(category_items), 1)
        self.assertEqual(category_items[0].id, "test_1")
    
    def test_get_category_items(self):
        """æµ‹è¯•è·å–åˆ†ç±»å†…å®¹é¡¹"""
        # å…ˆæ·»åŠ ä¸€äº›å†…å®¹é¡¹
        item1 = ContentItem(
            id="test_1", title="æµ‹è¯•1", content="å†…å®¹1",
            source_name="æ¥æº1", url="https://example.com/1", publish_time=datetime.now(), source_type="rss"
        )
        item2 = ContentItem(
            id="test_2", title="æµ‹è¯•2", content="å†…å®¹2",
            source_name="æ¥æº2", url="https://example.com/2", publish_time=datetime.now(), source_type="rss"
        )
        
        analysis1 = AnalysisResult("test_1", "å¤§æˆ·åŠ¨å‘", 0.9, "æ¨ç†1", False, [])
        analysis2 = AnalysisResult("test_2", "å¤§æˆ·åŠ¨å‘", 0.8, "æ¨ç†2", False, [])
        
        self.classifier.classify_item(item1, analysis1)
        self.classifier.classify_item(item2, analysis2)
        
        # æµ‹è¯•è·å–åˆ†ç±»å†…å®¹
        whale_items = self.classifier.get_category_items("å¤§æˆ·åŠ¨å‘")
        self.assertEqual(len(whale_items), 2)
        
        # æµ‹è¯•è·å–ä¸å­˜åœ¨çš„åˆ†ç±»
        empty_items = self.classifier.get_category_items("ä¸å­˜åœ¨çš„åˆ†ç±»")
        self.assertEqual(len(empty_items), 0)
    
    def test_generate_category_summary(self):
        """æµ‹è¯•ç”Ÿæˆåˆ†ç±»æ‘˜è¦"""
        # æ·»åŠ æµ‹è¯•å†…å®¹é¡¹
        for i in range(3):
            item = ContentItem(
                id=f"test_{i}",
                title=f"æµ‹è¯•æ ‡é¢˜{i}",
                content=f"æµ‹è¯•å†…å®¹{i}",
                source_name="æµ‹è¯•æ¥æº",
                url=f"https://example.com/test_{i}",
                publish_time=datetime.now(),
                source_type="rss"
            )
            analysis = AnalysisResult(f"test_{i}", "åˆ©ç‡äº‹ä»¶", 0.9, "æ¨ç†", False, [])
            self.classifier.classify_item(item, analysis)
        
        summary = self.classifier.generate_category_summary("åˆ©ç‡äº‹ä»¶")
        
        self.assertIn("åˆ©ç‡äº‹ä»¶", summary)
        self.assertIn("(3æ¡)", summary)
        self.assertIn("æµ‹è¯•æ ‡é¢˜0", summary)
        self.assertIn("æµ‹è¯•æ ‡é¢˜1", summary)
        self.assertIn("æµ‹è¯•æ ‡é¢˜2", summary)
    
    def test_clear_classifications(self):
        """æµ‹è¯•æ¸…ç©ºåˆ†ç±»ç»“æœ"""
        # å…ˆæ·»åŠ ä¸€äº›å†…å®¹
        item = ContentItem(
            id="test_1", title="æµ‹è¯•", content="å†…å®¹",
            source_name="æ¥æº", url="https://example.com/test", publish_time=datetime.now(), source_type="rss"
        )
        analysis = AnalysisResult("test_1", "å¤§æˆ·åŠ¨å‘", 0.9, "æ¨ç†", False, [])
        self.classifier.classify_item(item, analysis)
        
        # éªŒè¯æœ‰å†…å®¹
        self.assertEqual(len(self.classifier.get_category_items("å¤§æˆ·åŠ¨å‘")), 1)
        
        # æ¸…ç©ºåˆ†ç±»
        self.classifier.clear_classifications()
        
        # éªŒè¯å·²æ¸…ç©º
        self.assertEqual(len(self.classifier.get_category_items("å¤§æˆ·åŠ¨å‘")), 0)
    
    def test_get_classification_stats(self):
        """æµ‹è¯•è·å–åˆ†ç±»ç»Ÿè®¡ä¿¡æ¯"""
        # æ·»åŠ ä¸åŒåˆ†ç±»çš„å†…å®¹é¡¹
        categories = ["å¤§æˆ·åŠ¨å‘", "åˆ©ç‡äº‹ä»¶", "å®‰å…¨äº‹ä»¶"]
        counts = [2, 3, 1]
        
        for category, count in zip(categories, counts):
            for i in range(count):
                item = ContentItem(
                    id=f"{category}_{i}", title=f"æ ‡é¢˜{i}", content=f"å†…å®¹{i}",
                    source_name="æ¥æº", url=f"https://example.com/{category}_{i}", publish_time=datetime.now(), source_type="rss"
                )
                analysis = AnalysisResult(f"{category}_{i}", category, 0.9, "æ¨ç†", False, [])
                self.classifier.classify_item(item, analysis)
        
        stats = self.classifier.get_classification_stats()
        
        self.assertEqual(stats["å¤§æˆ·åŠ¨å‘"], 2)
        self.assertEqual(stats["åˆ©ç‡äº‹ä»¶"], 3)
        self.assertEqual(stats["å®‰å…¨äº‹ä»¶"], 1)


if __name__ == '__main__':
    # è¿è¡Œæµ‹è¯•
    unittest.main(verbosity=2)